{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-baltimore",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-regard",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "> Setup GPU, default paths & global variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-disposition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.imports import * \n",
    "from addict import Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-america",
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-storage",
   "metadata": {},
   "source": [
    "Every file in the library imports this, so all global set up required everywhere can be added here.\n",
    "1. Sets up device to GPU if available.\n",
    "2. Defines default paths for different stores - so that they are out of version control by default.\n",
    "3. Global scope variables - for convenience in other modules."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "african-perspective",
   "metadata": {},
   "source": [
    "## GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-liability",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "def get_device():\n",
    "    '''Checks to see if GPU is available and sets device to GPU or CPU'''\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    if use_cuda:\n",
    "        assert torch.backends.cudnn.enabled == True\n",
    "        torch.backends.cudnn.benchmark = True #Enable cuDNN auto-tuner - perf benefit for convs\n",
    "        device = torch.device(\"cuda\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    return device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_settings():\n",
    "    '''Read settings file at \"~/.lemonade/settings.yaml\", if doesnt exist, create it from template'''\n",
    "    settings_dir = f'{Path.home()}/.lemonade'\n",
    "    settings_file = Path(f'{settings_dir}/settings.yaml')\n",
    "\n",
    "    if not settings_file.exists():\n",
    "        print('No settings file found, so creating from template ..')\n",
    "        with open('./templates/settings_template.yaml', 'r') as t:\n",
    "            template = Dict(yaml.full_load(t))\n",
    "        template.STORES.DATA_STORE       = f'{Path.home()}/.lemonade/datasets'\n",
    "        template.STORES.LOG_STORE        = f'{Path.home()}/.lemonade/logs'\n",
    "        template.STORES.MODEL_STORE      = f'{Path.home()}/.lemonade/models'\n",
    "        template.STORES.EXPERIMENT_STORE = f'{Path.home()}/.lemonade/experiments'\n",
    "        \n",
    "        settings = template\n",
    "        Path.mkdir(Path(settings_dir), exist_ok=True)\n",
    "        with open(settings_file, 'w') as s:\n",
    "            yaml.dump(settings.to_dict(), s)\n",
    "    else:\n",
    "        with open(settings_file, 'r') as s:\n",
    "            settings = Dict(yaml.full_load(s))\n",
    "\n",
    "    return settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-metropolitan",
   "metadata": {},
   "source": [
    "## Global Scope Variables (Change Data Gen Dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manufactured-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "DEVICE = get_device()\n",
    "settings = read_settings()\n",
    "\n",
    "DATA_STORE         = settings.STORES.DATA_STORE\n",
    "LOG_STORE          = settings.STORES.LOG_STORE\n",
    "MODEL_STORE        = settings.STORES.MODEL_STORE\n",
    "EXPERIMENT_STORE   = settings.STORES.EXPERIMENT_STORE\n",
    "\n",
    "PATH_1K   = f'{DATA_STORE}/synthea/1K'\n",
    "PATH_10K  = f'{DATA_STORE}/synthea/10K'\n",
    "PATH_20K  = f'{DATA_STORE}/synthea/20K'\n",
    "PATH_100K = f'{DATA_STORE}/synthea/100K'\n",
    "\n",
    "FILENAMES = settings.FILENAMES\n",
    "\n",
    "SYNTHEA_DATAGEN_DATES = settings.SYNTHEA_DATAGEN_DATES\n",
    "\n",
    "CONDITIONS = settings.CONDITIONS\n",
    "\n",
    "LABELS = settings.LABELS\n",
    "\n",
    "LOG_NUMERICALIZE_EXCEP = settings.LOG_NUMERICALIZE_EXCEP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "twenty-exchange",
   "metadata": {},
   "source": [
    "- These are global variables used (in this initial release of the library) for convenience in other places; this will be cleaned up in future releases.\n",
    "- The only things that need changing here are the `SYNTHEA_DATAGEN_DATES`.\n",
    "    - Please update them based on when you generate a particular dataset.\n",
    "    - These dates are important to calculate patient age.\n",
    "- `CONDITIONS` and `LABELS` go hand-in-hand\n",
    "    - These are the labels we are trying to predict with the deep learning models.\n",
    "    - `CONDITIONS` is how they appear in the preprocessed dataset.\n",
    "    - `LABELS` is a convenient list used everywhere for display & ploting purposes (again will be cleaned up in future)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-europe",
   "metadata": {},
   "source": [
    "### Stores - Default Paths (Change These)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-arctic",
   "metadata": {},
   "source": [
    "**Please change these paths to defaults in your specific configuration**\n",
    "\n",
    "- All of these artifacts need to be in some form of failsafe storage, but not all need to be in version control.\n",
    "- Also, some of them are likely to get big and version control might not be the ideal location (e.g. data, logs and models).\n",
    "    - Experiments on the other hand, as designed here, tend to be small-sized enough and can be stored in github or some other version control system (VCS).\n",
    "    - Each Experiment will keep track of the model it runs and saves it separately in the model store.\n",
    "    - Given the nature of the dataset in this release of the library (synthetic / Synthea), it can be easily re-generated in case of a loss.\n",
    "    \n",
    "So, its left to the user to decide which store needs to be where, depending upon your decision, change the default paths here.<br>\n",
    "**Recommendation** is to store experiments in some VCS and data & models in some type of failsafe storage; logs are used minimally and not that important (atleast in this release)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greater-luxury",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vinod/.lemonade/datasets'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_STORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-involvement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/vinod/.lemonade/models'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_STORE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-burlington",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-samuel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_setup.ipynb.\n",
      "Converted 01_preprocessing_clean.ipynb.\n",
      "Converted 02_preprocessing_vocab.ipynb.\n",
      "Converted 03_preprocessing_transform.ipynb.\n",
      "Converted 04_data.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted 06_learn.ipynb.\n",
      "Converted 07_models.ipynb.\n",
      "Converted 08_experiment.ipynb.\n",
      "Converted 09_Tmp_CNN.ipynb.\n",
      "Converted 09_Tmp_LSTM.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-charleston",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
