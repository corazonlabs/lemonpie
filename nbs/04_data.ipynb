{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "> Classes and functions for managing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from lemonpie.basics import *\n",
    "from lemonpie.preprocessing.transform import *\n",
    "from fastai.imports import *\n",
    "import copy, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting is already done in the raw data before vocab creation.\n",
    "- The following class is to load and manage the pre-processed splits together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EHRDataSplits:\n",
    "    \"\"\"Class to hold the PatientList splits.\"\"\"\n",
    "\n",
    "    def __init__(self, path, age_start, age_range, start_is_date, age_in_months):\n",
    "\n",
    "        self.splits, self.modality_types = self._load_splits(\n",
    "            path, age_start, age_range, start_is_date, age_in_months\n",
    "        )\n",
    "        # self.train, self.valid, self.test = self.splits.values()\n",
    "\n",
    "    def _load_splits(self, path, age_start, age_range, start_is_date, age_in_months):\n",
    "        \"\"\"Load splits of preprocessed `PatientList`s from persistent store using path.\"\"\"\n",
    "        splits = {}\n",
    "        modality_types = {}\n",
    "        for split in [\"train\", \"valid\", \"test\"]:\n",
    "            pckl_dir = get_pckl_dir(\n",
    "                path, split, 999, age_start, age_range, age_in_months\n",
    "            )\n",
    "            mod_types = [\n",
    "                mod_type.name.split(\"_\")[-1] for mod_type in pckl_dir.parent.iterdir()\n",
    "            ]\n",
    "\n",
    "            modality_types[split] = mod_types\n",
    "            splits[split] = [\n",
    "                PatientList.load(\n",
    "                    path=path,\n",
    "                    split=split,\n",
    "                    modality_type=m_type,\n",
    "                    age_start=age_start,\n",
    "                    age_range=age_range,\n",
    "                    start_is_date=start_is_date,\n",
    "                    age_in_months=age_in_months,\n",
    "                )\n",
    "                for m_type in mod_types\n",
    "            ]\n",
    "\n",
    "        return splits, modality_types\n",
    "\n",
    "    def get_splits_modtypes(self):\n",
    "        \"\"\"Return splits and modality types.\"\"\"\n",
    "        return self.splits, self.modality_types\n",
    "\n",
    "    def get_lengths(self):\n",
    "        \"\"\"Return a dataframe with lengths (# of patients) of the splits (train, valid, test) and total.\"\"\"\n",
    "        lengths = []\n",
    "        train, valid, test = self.splits.values()\n",
    "\n",
    "        for split in [train, valid, test]:\n",
    "            lengths.append(sum([len(ptlist) for ptlist in split]))\n",
    "        lengths.append(sum(lengths))\n",
    "        return pd.DataFrame(\n",
    "            lengths, index=[\"train\", \"valid\", \"test\", \"total\"], columns=[\"lengths\"]\n",
    "        )\n",
    "\n",
    "    def get_label_counts(self, labels):\n",
    "        \"\"\"Get prevalence counts of labels in each split \n",
    "        returns a dataframe with counts for each split and total count.\"\"\"\n",
    "\n",
    "        train, valid, test = self.splits.values()\n",
    "\n",
    "        # flatten for each split\n",
    "        train_ptlist = [ptlist for mod_type in train for ptlist in mod_type]\n",
    "        valid_ptlist = [ptlist for mod_type in valid for ptlist in mod_type]\n",
    "        test_ptlist = [ptlist for mod_type in test for ptlist in mod_type]\n",
    "\n",
    "        counts = []\n",
    "        for label in labels:\n",
    "            train_count = [\n",
    "                train_ptlist[i].conditions[label] == 1 for i in range(len(train_ptlist))\n",
    "            ].count(True)\n",
    "            valid_count = [\n",
    "                valid_ptlist[i].conditions[label] == 1 for i in range(len(valid_ptlist))\n",
    "            ].count(True)\n",
    "            test_count = [\n",
    "                test_ptlist[i].conditions[label] == 1 for i in range(len(test_ptlist))\n",
    "            ].count(True)\n",
    "            total_count = train_count + valid_count + test_count\n",
    "            counts.append([train_count, valid_count, test_count, total_count])\n",
    "        return pd.DataFrame(\n",
    "            counts, index=labels, columns=[\"train\", \"valid\", \"test\", \"total\"]\n",
    "        )\n",
    "\n",
    "    def get_pos_wts(self, labels):\n",
    "        \"\"\"Get positive weights to be used in `nn.BCEWithLogitsLoss`.\"\"\"\n",
    "        pos_counts = self.get_label_counts(labels)\n",
    "        neg_counts = self.get_lengths().transpose().values - pos_counts\n",
    "        return round(neg_counts / pos_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"EHRDataSplits\" class=\"doc_header\"><code>class</code> <code>EHRDataSplits</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>EHRDataSplits</code>(**`path`**, **`age_start`**, **`age_range`**, **`start_is_date`**, **`age_in_months`**)\n",
       "\n",
       "Class to hold the PatientList splits."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits._load_splits\" class=\"doc_header\"><code>EHRDataSplits._load_splits</code><a href=\"__main__.py#L12\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits._load_splits</code>(**`path`**, **`age_start`**, **`age_range`**, **`start_is_date`**, **`age_in_months`**)\n",
       "\n",
       "Load splits of preprocessed [`PatientList`](/lemonpie/preprocessing_transform.html#PatientList)s from persistent store using path."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits._load_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_splits_modtypes\" class=\"doc_header\"><code>EHRDataSplits.get_splits_modtypes</code><a href=\"__main__.py#L40\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_splits_modtypes</code>()\n",
       "\n",
       "Return splits and modality types."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_splits_modtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_lengths\" class=\"doc_header\"><code>EHRDataSplits.get_lengths</code><a href=\"__main__.py#L44\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_lengths</code>()\n",
       "\n",
       "Return a dataframe with lengths (# of patients) of the splits (train, valid, test) and total."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_label_counts\" class=\"doc_header\"><code>EHRDataSplits.get_label_counts</code><a href=\"__main__.py#L56\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_label_counts</code>(**`labels`**)\n",
       "\n",
       "Get prevalence counts of labels in each split \n",
       "returns a dataframe with counts for each split and total count."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_pos_wts\" class=\"doc_header\"><code>EHRDataSplits.get_pos_wts</code><a href=\"__main__.py#L84\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_pos_wts</code>(**`labels`**)\n",
       "\n",
       "Get positive weights to be used in `nn.BCEWithLogitsLoss`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_pos_wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests on Synthea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/vinod/.lemonpie/datasets/synthea/1K',\n",
       " {'diabetes': '44054006',\n",
       "  'stroke': '230690007',\n",
       "  'alzheimers': '26929004',\n",
       "  'coronary_heart': '53741008',\n",
       "  'lung_cancer': '254637007',\n",
       "  'breast_cancer': '254837009',\n",
       "  'rheumatoid_arthritis': '69896004',\n",
       "  'epilepsy': '84757009'})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_1K, CONDITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(CONDITIONS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diabetes',\n",
       " 'stroke',\n",
       " 'alzheimers',\n",
       " 'coronary_heart',\n",
       " 'lung_cancer',\n",
       " 'breast_cancer',\n",
       " 'rheumatoid_arthritis',\n",
       " 'epilepsy']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits = EHRDataSplits(PATH_1K, age_start='2000-01-01', age_range=17, start_is_date=True, age_in_months=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>1171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lengths\n",
       "train      702\n",
       "valid      234\n",
       "test       235\n",
       "total     1171"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = splits.get_lengths()\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alzheimers</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronary_heart</th>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lung_cancer</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rheumatoid_arthritis</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epilepsy</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      train  valid  test  total\n",
       "diabetes                 43     14    19     76\n",
       "stroke                   30      7    11     48\n",
       "alzheimers               12      7     6     25\n",
       "coronary_heart           39     11    11     61\n",
       "lung_cancer              12      0     2     14\n",
       "breast_cancer            11      8     2     21\n",
       "rheumatoid_arthritis      2      0     0      2\n",
       "epilepsy                 15      5     2     22"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalence = splits.get_label_counts(labels)\n",
    "prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alzheimers</th>\n",
       "      <td>58.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronary_heart</th>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lung_cancer</th>\n",
       "      <td>58.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>116.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>63.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rheumatoid_arthritis</th>\n",
       "      <td>350.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epilepsy</th>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      train  valid   test  total\n",
       "diabetes               15.0   16.0   11.0   14.0\n",
       "stroke                 22.0   32.0   20.0   23.0\n",
       "alzheimers             58.0   32.0   38.0   46.0\n",
       "coronary_heart         17.0   20.0   20.0   18.0\n",
       "lung_cancer            58.0    inf  116.0   83.0\n",
       "breast_cancer          63.0   28.0  116.0   55.0\n",
       "rheumatoid_arthritis  350.0    inf    inf  584.0\n",
       "epilepsy               46.0   46.0  116.0   52.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits.get_pos_wts(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 702,  234,  235, 1171]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths.transpose().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>659</td>\n",
       "      <td>220</td>\n",
       "      <td>216</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>672</td>\n",
       "      <td>227</td>\n",
       "      <td>224</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alzheimers</th>\n",
       "      <td>690</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronary_heart</th>\n",
       "      <td>663</td>\n",
       "      <td>223</td>\n",
       "      <td>224</td>\n",
       "      <td>1110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lung_cancer</th>\n",
       "      <td>690</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>1157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>691</td>\n",
       "      <td>226</td>\n",
       "      <td>233</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rheumatoid_arthritis</th>\n",
       "      <td>700</td>\n",
       "      <td>234</td>\n",
       "      <td>235</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epilepsy</th>\n",
       "      <td>687</td>\n",
       "      <td>229</td>\n",
       "      <td>233</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      train  valid  test  total\n",
       "diabetes                659    220   216   1095\n",
       "stroke                  672    227   224   1123\n",
       "alzheimers              690    227   229   1146\n",
       "coronary_heart          663    223   224   1110\n",
       "lung_cancer             690    234   233   1157\n",
       "breast_cancer           691    226   233   1150\n",
       "rheumatoid_arthritis    700    234   235   1169\n",
       "epilepsy                687    229   233   1149"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_counts = lengths.transpose().values - prevalence\n",
    "neg_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alzheimers</th>\n",
       "      <td>58.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronary_heart</th>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lung_cancer</th>\n",
       "      <td>58.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>116.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>63.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rheumatoid_arthritis</th>\n",
       "      <td>350.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epilepsy</th>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      train  valid   test  total\n",
       "diabetes               15.0   16.0   11.0   14.0\n",
       "stroke                 22.0   32.0   20.0   23.0\n",
       "alzheimers             58.0   32.0   38.0   46.0\n",
       "coronary_heart         17.0   20.0   20.0   18.0\n",
       "lung_cancer            58.0    inf  116.0   83.0\n",
       "breast_cancer          63.0   28.0  116.0   55.0\n",
       "rheumatoid_arthritis  350.0    inf    inf  584.0\n",
       "epilepsy               46.0   46.0  116.0   52.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(neg_counts / prevalence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross check with raw**\n",
    "- Check total counts against raw_csv\n",
    "- Check split counts against split/raw_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cnds = pd.read_csv(f'{PATH_1K}/raw_original/conditions.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['44054006',\n",
       " '230690007',\n",
       " '26929004',\n",
       " '53741008',\n",
       " '254637007',\n",
       " '254837009',\n",
       " '69896004',\n",
       " '84757009']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnd_codes = list(CONDITIONS.values())\n",
    "cnd_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44054006"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(CONDITIONS['diabetes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes ::  76\n",
      "stroke ::  48\n",
      "alzheimers ::  25\n",
      "coronary_heart ::  61\n",
      "lung_cancer ::  14\n",
      "breast_cancer ::  21\n",
      "rheumatoid_arthritis ::  2\n",
      "epilepsy ::  22\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print(label,':: ', raw_cnds[raw_cnds.CODE == int(CONDITIONS[label])].CODE.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cnds_train = pd.read_csv(f'{PATH_1K}/raw_split/train/conditions.csv', low_memory=False)\n",
    "raw_cnds_valid = pd.read_csv(f'{PATH_1K}/raw_split/valid/conditions.csv', low_memory=False)\n",
    "raw_cnds_test  = pd.read_csv(f'{PATH_1K}/raw_split/test/conditions.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    assert prevalence.loc[label].total == raw_cnds[raw_cnds.CODE == int(CONDITIONS[label])].CODE.count()\n",
    "    assert prevalence.loc[label].train == raw_cnds_train[raw_cnds_train.CODE == int(CONDITIONS[label])].CODE.count()\n",
    "    assert prevalence.loc[label].valid == raw_cnds_valid[raw_cnds_valid.CODE == int(CONDITIONS[label])].CODE.count()\n",
    "    assert prevalence.loc[label].test  == raw_cnds_test [raw_cnds_test.CODE == int(CONDITIONS[label])]. CODE.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests on Coherent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COHERENT_DATA_STORE = '/home/vinod/code/datasets/coherent'\n",
    "COHERENT_DATAGEN_DATE = '08-10-2021'\n",
    "COHERENT_CONDITIONS = {\n",
    "    \"heart_failure\" : \"88805009\",\n",
    "    \"coronary_heart\" : \"53741008\",\n",
    "    \"myocardial_infarction\" : \"22298006\",\n",
    "    \"stroke\" : \"230690007\",\n",
    "    \"cardiac_arrest\" : \"410429000\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(COHERENT_CONDITIONS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['heart_failure',\n",
       " 'coronary_heart',\n",
       " 'myocardial_infarction',\n",
       " 'stroke',\n",
       " 'cardiac_arrest']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherent_splits = EHRDataSplits(COHERENT_DATA_STORE,  age_start=240, age_range=120, start_is_date=False, age_in_months=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>1022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>1278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lengths\n",
       "train     1022\n",
       "valid      128\n",
       "test       128\n",
       "total     1278"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = coherent_splits.get_lengths()\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>heart_failure</th>\n",
       "      <td>257</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronary_heart</th>\n",
       "      <td>260</td>\n",
       "      <td>38</td>\n",
       "      <td>38</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>myocardial_infarction</th>\n",
       "      <td>110</td>\n",
       "      <td>15</td>\n",
       "      <td>20</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>573</td>\n",
       "      <td>61</td>\n",
       "      <td>64</td>\n",
       "      <td>698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardiac_arrest</th>\n",
       "      <td>137</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       train  valid  test  total\n",
       "heart_failure            257     43    32    332\n",
       "coronary_heart           260     38    38    336\n",
       "myocardial_infarction    110     15    20    145\n",
       "stroke                   573     61    64    698\n",
       "cardiac_arrest           137     20    23    180"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalence = coherent_splits.get_label_counts(labels)\n",
    "prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>heart_failure</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronary_heart</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>myocardial_infarction</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardiac_arrest</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       train  valid  test  total\n",
       "heart_failure            3.0    2.0   3.0    3.0\n",
       "coronary_heart           3.0    2.0   2.0    3.0\n",
       "myocardial_infarction    8.0    8.0   5.0    8.0\n",
       "stroke                   1.0    1.0   1.0    1.0\n",
       "cardiac_arrest           6.0    5.0   5.0    6.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coherent_splits.get_pos_wts(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1022,  128,  128, 1278]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths.transpose().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>heart_failure</th>\n",
       "      <td>765</td>\n",
       "      <td>85</td>\n",
       "      <td>96</td>\n",
       "      <td>946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronary_heart</th>\n",
       "      <td>762</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>myocardial_infarction</th>\n",
       "      <td>912</td>\n",
       "      <td>113</td>\n",
       "      <td>108</td>\n",
       "      <td>1133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>449</td>\n",
       "      <td>67</td>\n",
       "      <td>64</td>\n",
       "      <td>580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardiac_arrest</th>\n",
       "      <td>885</td>\n",
       "      <td>108</td>\n",
       "      <td>105</td>\n",
       "      <td>1098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       train  valid  test  total\n",
       "heart_failure            765     85    96    946\n",
       "coronary_heart           762     90    90    942\n",
       "myocardial_infarction    912    113   108   1133\n",
       "stroke                   449     67    64    580\n",
       "cardiac_arrest           885    108   105   1098"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_counts = lengths.transpose().values - prevalence\n",
    "neg_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>heart_failure</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronary_heart</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>myocardial_infarction</th>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardiac_arrest</th>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       train  valid  test  total\n",
       "heart_failure            3.0    2.0   3.0    3.0\n",
       "coronary_heart           3.0    2.0   2.0    3.0\n",
       "myocardial_infarction    8.0    8.0   5.0    8.0\n",
       "stroke                   1.0    1.0   1.0    1.0\n",
       "cardiac_arrest           6.0    5.0   5.0    6.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(neg_counts / prevalence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross check with raw**\n",
    "- Check total counts against raw_csv\n",
    "- Check split counts against split/raw_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cnds = pd.read_csv(f'{COHERENT_DATA_STORE}/raw_original/conditions.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['88805009', '53741008', '22298006', '230690007', '410429000']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnd_codes = list(COHERENT_CONDITIONS.values())\n",
    "cnd_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "heart_failure ::  332\n",
      "coronary_heart ::  336\n",
      "myocardial_infarction ::  145\n",
      "stroke ::  698\n",
      "cardiac_arrest ::  180\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print(label,':: ', raw_cnds[raw_cnds.CODE == int(COHERENT_CONDITIONS[label])].CODE.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cnds_train = pd.read_csv(f'{COHERENT_DATA_STORE}/raw_split/train/conditions.csv', low_memory=False)\n",
    "raw_cnds_valid = pd.read_csv(f'{COHERENT_DATA_STORE}/raw_split/valid/conditions.csv', low_memory=False)\n",
    "raw_cnds_test  = pd.read_csv(f'{COHERENT_DATA_STORE}/raw_split/test/conditions.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    assert prevalence.loc[label].total == raw_cnds[raw_cnds.CODE == int(COHERENT_CONDITIONS[label])].CODE.count()\n",
    "    assert prevalence.loc[label].train == raw_cnds_train[raw_cnds_train.CODE == int(COHERENT_CONDITIONS[label])].CODE.count()\n",
    "    assert prevalence.loc[label].valid == raw_cnds_valid[raw_cnds_valid.CODE == int(COHERENT_CONDITIONS[label])].CODE.count()\n",
    "    assert prevalence.loc[label].test  == raw_cnds_test [raw_cnds_test.CODE == int(COHERENT_CONDITIONS[label])]. CODE.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labeling** definition in fastai -- some processes need to be run on `train` and **applied** to `valid`\n",
    "\n",
    "This is completed in preprocessing (vocab & transform) as follows\n",
    "1. Vocabs created from train data\n",
    "    - Tokenizing unique values for different record codes & demographic values\n",
    "    - Calculating mean and std for age\n",
    "2. Vocabs applied to train, valid and test data\n",
    "    - With `numericalize` for record codes & demographic values\n",
    "    - With normalizing of age with the mean / std from train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hence labeling in our case will be creating X and y**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X is the patient object\n",
    "- y (for a single patient) needs to be a tensor made out of the patient's values for labels ('diabetes', 'stroke', 'alzheimers', 'coronary_heart', 'lung_cancer') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So **creating the `y` tensor** is simply a matter of ..\n",
    "1. extracting the values of each of the labels from each `Patient` object \n",
    "2. turning it into a `torch.FloatTensor`\n",
    "3. and stacking them up using `torch.stack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 0., 0., 1.], dtype=torch.float64), tensor([1., 0., 0., 1.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_y = np.array((True, False, False, True), dtype='float')\n",
    "torch.from_numpy(tst_y), torch.FloatTensor(tst_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 ways of creating torch tensor from a numpy array, we will stick with the latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for pt in splits.valid[0]:\n",
    "    y.append(torch.FloatTensor(np.array([pt.conditions[label] for label in labels], dtype='float')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(patient_ds, labels) -> 'x,y':\n",
    "    '''Extracts y from patient object, returns x=Patient object, y=tensor of conditions'''\n",
    "    def _get_y(ds, labels):\n",
    "        y = []\n",
    "        for pt in ds:\n",
    "            y.append( torch.FloatTensor(np.array([pt.conditions[label] for label in labels], dtype='float')) )\n",
    "        return torch.stack(y)\n",
    "    \n",
    "    x, y = patient_ds, _get_y(patient_ds, labels)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = label_data(splits.train, labels)\n",
    "x_valid,y_valid = label_data(splits.valid, labels)\n",
    "x_test ,y_test  = label_data(splits.test , labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([702, 8]), torch.Size([234, 8]), torch.Size([235, 8]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((10,1), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LabelEHRData():\n",
    "    '''Class to hold labeled EHR data splits'''\n",
    "    def __init__(self, train, valid, test, labels):\n",
    "        '''Extracts y from patient object, each labelset a tuple of x,y: x=Patient object, y=tensor of conditions'''\n",
    "        self.x_train, self.y_train = train, self._get_y(train, labels)\n",
    "        self.x_valid, self.y_valid = valid, self._get_y(valid, labels)\n",
    "        self.x_test,  self.y_test  = test , self._get_y(test , labels)\n",
    "        \n",
    "        self.train = self.x_train, self.y_train\n",
    "        self.valid = self.x_valid, self.y_valid\n",
    "        self.test  = self.x_test,  self.y_test\n",
    "    \n",
    "    def _get_y(self, ds, labels):\n",
    "        '''Extract y from each patient object in ds and stack them - ds is dataset containing patient objects'''\n",
    "        y = []\n",
    "        for pt in ds:\n",
    "            y.append( torch.FloatTensor(np.array([pt.conditions[label] for label in labels], dtype='float')) )\n",
    "        return torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"LabelEHRData\" class=\"doc_header\"><code>class</code> <code>LabelEHRData</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>LabelEHRData</code>(**`train`**, **`valid`**, **`test`**, **`labels`**)\n",
       "\n",
       "Class to hold labeled EHR data splits"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LabelEHRData, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LabelEHRData.__init__\" class=\"doc_header\"><code>LabelEHRData.__init__</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>LabelEHRData.__init__</code>(**`train`**, **`valid`**, **`test`**, **`labels`**)\n",
       "\n",
       "Extracts y from patient object, each labelset a tuple of x,y: x=Patient object, y=tensor of conditions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LabelEHRData.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LabelEHRData._get_y\" class=\"doc_header\"><code>LabelEHRData._get_y</code><a href=\"__main__.py#L14\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>LabelEHRData._get_y</code>(**`ds`**, **`labels`**)\n",
       "\n",
       "Extract y from each patient object in ds and stack them - ds is dataset containing patient objects"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LabelEHRData._get_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = LabelEHRData(*splits.get_splits(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PatientList (702 items)\n",
       " base path:/home/vinod/.lemonpie/datasets/synthea/1K; split:train\n",
       " age_start:2000-01-01; age_range:17; age_type:years\n",
       " ptid:0ace3e15-8aa4-41c5-8b90-2408285ebcfe, birthdate:1986-04-02 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:af1495be-5077-4087-98b1-9ff624c7582c, birthdate:2008-07-17 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:f23e12d9-2ec6-4006-b041-ea78d374e9c9, birthdate:2014-09-06 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:1968aa31-5fce-461a-9486-6e385a7b75e7, birthdate:1986-04-11 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:1211c8ff-ab73-49f3-b2ab-87b7a03f6167, birthdate:1972-03-24 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:27a8b7b6-007d-4036-82a7-80a9ab670dcb, birthdate:2005-04-13 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:532696f2-0b76-4eb0-9aea-a74e2fb1bed2, birthdate:1967-05-18 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:8641e13a-c832-4d97-811a-b735d0abb45e, birthdate:1982-10-06 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:7f874045-4062-405d-8c23-abb12d0af23e, birthdate:1972-05-20 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:0b6a83ae-fcb1-4b75-9ffa-d52898167d66, birthdate:1989-08-05 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu...],\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled.train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Subclasses](https://pytorch.org/docs/master/data.html?highlight=dataloader#torch.utils.data.Dataset) `torch.utils.data.Dataset`<br>\n",
    "- that is implements `__len__()` and `__getitem__()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EHRDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Class to hold a single EHR dataset (holds a tuple of x, y & m for modality type).\n",
    "    Also handles lazy vs full loading of dataset on GPU.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        ptlist: list,\n",
    "        labels: list,\n",
    "        modality_type: int,\n",
    "        lazy_load_gpu: bool = True,\n",
    "    ):\n",
    "        \"\"\"Extract y, create x,y: x=Patient object, y=tensor of conditions\n",
    "        If `lazy_load_gpu` is `False`, load entire dataset on GPU.\"\"\"\n",
    "\n",
    "        self.x, self.y = ptlist, self._get_y(ptlist, labels)\n",
    "        # self.m = torch.full((len(ptlist), 1), modality_type)\n",
    "        self.m = modality_type\n",
    "        self.lazy = lazy_load_gpu\n",
    "\n",
    "        if self.lazy == False:\n",
    "            self.x = [pt.to_gpu() for pt in self.x]\n",
    "            self.y = self.y.to(DEVICE)\n",
    "            self.m = self.m.to(DEVICE)\n",
    "\n",
    "    def _get_y(self, ptlist, labels):\n",
    "        \"\"\"Extract y from each patient object in ptlist and stack them.\"\"\"\n",
    "        y = []\n",
    "        for pt in ptlist:\n",
    "            y.append(\n",
    "                torch.FloatTensor(\n",
    "                    np.array([pt.conditions[label] for label in labels], dtype=\"float\")\n",
    "                )\n",
    "            )\n",
    "        return torch.stack(y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def _test_getitem(self, i):\n",
    "        return self.x[i], self.y[i], self.m\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"If lazy loading, return deep copy of patient object `i`\n",
    "        else entire dataset already on GPU - just return `i`.\"\"\"\n",
    "        if self.lazy:\n",
    "            return copy.deepcopy(self.x[i]), self.y[i], self.m  # make m[i] if tensor\n",
    "        else:\n",
    "            return self.x[i], self.y[i], self.m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"EHRDataset\" class=\"doc_header\"><code>class</code> <code>EHRDataset</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>EHRDataset</code>(**\\*`args`**, **\\*\\*`kwds`**) :: `Dataset`\n",
       "\n",
       "Class to hold a single EHR dataset (holds a tuple of x, y & m for modality type).\n",
       "Also handles lazy vs full loading of dataset on GPU."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataset, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataset.__init__\" class=\"doc_header\"><code>EHRDataset.__init__</code><a href=\"__main__.py#L6\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataset.__init__</code>(**`ptlist`**:`list`, **`labels`**:`list`, **`modality_type`**:`int`, **`lazy_load_gpu`**:`bool`=*`True`*)\n",
       "\n",
       "Extract y, create x,y: x=Patient object, y=tensor of conditions\n",
       "If `lazy_load_gpu` is `False`, load entire dataset on GPU."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataset.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataset._get_y\" class=\"doc_header\"><code>EHRDataset._get_y</code><a href=\"__main__.py#L26\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataset._get_y</code>(**`ptlist`**, **`labels`**)\n",
       "\n",
       "Extract y from each patient object in ptlist and stack them."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataset._get_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataset.__getitem__\" class=\"doc_header\"><code>EHRDataset.__getitem__</code><a href=\"__main__.py#L43\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataset.__getitem__</code>(**`i`**)\n",
       "\n",
       "If lazy loading, return deep copy of patient object `i`\n",
       "else entire dataset already on GPU - just return `i`."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataset.__getitem__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `Patient` is a custom object and not a typical tensor, we need to handle the behavior for `Dataset`, `DataLoader`, etc to function correctly.\n",
    "- Memory pinning is a good idea for better performance if lazy loading to GPU\n",
    "    - [A discussion - pin memory vs full load to GPU](https://discuss.pytorch.org/t/pin-memory-vs-sending-direct-to-gpu-from-dataset/33891)\n",
    "- So when a DataLoader pins memory on a tensor and copy of the tensor is made on page-locked memory in RAM as opposed to swappable memory which speed up transfers to GPU\n",
    "    - [A good explanation](https://stackoverflow.com/questions/5736968/why-is-cuda-pinned-memory-so-fast)\n",
    "- But on custom data type like our `Patient` object, we need to define the behavior\n",
    "    - [Pytorch docs](https://pytorch.org/docs/stable/data.html#memory-pinning)\n",
    "- Making a [deep copy](https://docs.python.org/3/library/copy.html) of the `Patient`object to mimick tensor behavior\n",
    "    - Otherwise, given the Patient holds it's changed tensors, all tensors are CUDA tensors after the first epoch and DL tries to pin memory again and this causes an error (TODO: Need to elaborate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Multimodal Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split-level Dataset & Custom Batch Sampler - one each for train, valid & test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each split (train, valid and test), we use  \n",
    "- a `ConcatDataset` to hold multiple `MultimodalDataset`s.\n",
    "- a custom batch sampler `ModalityTypeBatchSampler` that creates batches with the same modality type.\n",
    "\n",
    "Modality type is the combination of data modalities available for a given patient.\n",
    "| Modality Type | Modalities            |   \n",
    "|---\t        |---\t                |\n",
    "| **0**\t        | **EHR**               |\n",
    "| **1**         | EHR + **MRI**         |\n",
    "| **10**        | EHR + **DNA**         |      \n",
    "| 11   \t        | EHR + MRI + DNA       |\n",
    "| **20**        | EHR + **ECG**         |\n",
    "| 21            | EHR + MRI + ECG       |\n",
    "| 30            | EHR + DNA + ECG       |\n",
    "| 31            | EHR + MRI + DNA + ECG |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Solution used here is from this Pytorch forum discussion \n",
    "- https://discuss.pytorch.org/t/how-to-concatenate-different-datasets-each-with-different-dimensions/123218\n",
    "- The `ConcatDataset` holds all the specific `MultimodalDataset`s together - one for each modality combination.\n",
    "    - For example - (EHR + MRI + ECG + Notes), (EHR + MRI), (EHR + DNA + MRI + Notes), etc. \n",
    "- The custom batch sampler ensures that each batch only has elements from one of the `MultimodalDataset`s.\n",
    "    - But also provides shuffling across the various types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "class ModalityTypeBatchSampler(Sampler):\n",
    "    \"\"\"Custom BatchSampler for multimodal data.\"\"\"\n",
    "\n",
    "    def __init__(self, indices_list: list, batch_size: int, shuffle: bool):\n",
    "        \"\"\"Init with indicies from every modality-type dataset and create all batches.\"\"\"\n",
    "        self.indices_list = indices_list\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.all_batches = self._create_batches()\n",
    "\n",
    "    def _chunk(self, indices, size):\n",
    "        \"\"\"Chunk indices into batch size.\"\"\"\n",
    "        return torch.split(torch.tensor(indices), size)\n",
    "\n",
    "    def _create_batches(self):\n",
    "        \"\"\"Create batches.\"\"\"\n",
    "        all_batches = []\n",
    "        for indices in self.indices_list:\n",
    "            if self.shuffle:\n",
    "                random.shuffle(indices)\n",
    "            all_batches.extend(self._chunk(indices, self.batch_size))\n",
    "        all_batches = [batch.tolist() for batch in all_batches]\n",
    "\n",
    "        return all_batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterable used by dataloaders.\"\"\"\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.all_batches)\n",
    "        return iter(self.all_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return length based on concated datasets.\"\"\"\n",
    "        return len(self.all_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"ModalityTypeBatchSampler\" class=\"doc_header\"><code>class</code> <code>ModalityTypeBatchSampler</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>ModalityTypeBatchSampler</code>(**\\*`args`**, **\\*\\*`kwds`**) :: `Sampler`\n",
       "\n",
       "Custom BatchSampler for multimodal data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ModalityTypeBatchSampler, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ModalityTypeBatchSampler.__init__\" class=\"doc_header\"><code>ModalityTypeBatchSampler.__init__</code><a href=\"__main__.py#L7\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ModalityTypeBatchSampler.__init__</code>(**`indices_list`**:`list`, **`batch_size`**:`int`, **`shuffle`**:`bool`)\n",
       "\n",
       "Init with indicies from every modality-type dataset and create all batches."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ModalityTypeBatchSampler.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ModalityTypeBatchSampler._chunk\" class=\"doc_header\"><code>ModalityTypeBatchSampler._chunk</code><a href=\"__main__.py#L14\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ModalityTypeBatchSampler._chunk</code>(**`indices`**, **`size`**)\n",
       "\n",
       "Chunk indices into batch size."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ModalityTypeBatchSampler._chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ModalityTypeBatchSampler._create_batches\" class=\"doc_header\"><code>ModalityTypeBatchSampler._create_batches</code><a href=\"__main__.py#L18\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ModalityTypeBatchSampler._create_batches</code>()\n",
       "\n",
       "Create batches."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ModalityTypeBatchSampler._create_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ModalityTypeBatchSampler.__iter__\" class=\"doc_header\"><code>ModalityTypeBatchSampler.__iter__</code><a href=\"__main__.py#L29\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ModalityTypeBatchSampler.__iter__</code>()\n",
       "\n",
       "Iterable used by dataloaders."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ModalityTypeBatchSampler.__iter__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ModalityTypeBatchSampler.__len__\" class=\"doc_header\"><code>ModalityTypeBatchSampler.__len__</code><a href=\"__main__.py#L35\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ModalityTypeBatchSampler.__len__</code>()\n",
       "\n",
       "Return length based on concated datasets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ModalityTypeBatchSampler.__len__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_modality_ds_sampler(\n",
    "    ehr_dataset_list: list, batch_size: int, shuffle: bool\n",
    "):\n",
    "    \"\"\"Create a custom ConcatDataset and BatchSampler for modality types.\"\"\"\n",
    "\n",
    "    modtype_dataset = torch.utils.data.ConcatDataset(ehr_dataset_list)\n",
    "    indxs = modtype_dataset.cumulative_sizes\n",
    "\n",
    "    indicies_list = []\n",
    "    for i in range(len(ehr_dataset_list)):\n",
    "        if i == 0:\n",
    "            indx_range = range(indxs[0])\n",
    "        else:\n",
    "            indx_range = range(indxs[i - 1], indxs[i])\n",
    "        indicies_list.append(list(indx_range))\n",
    "\n",
    "    batch_sampler = ModalityTypeBatchSampler(indicies_list, batch_size, shuffle)\n",
    "\n",
    "    return modtype_dataset, batch_sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"create_modality_ds_sampler\" class=\"doc_header\"><code>create_modality_ds_sampler</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>create_modality_ds_sampler</code>(**`ehr_dataset_list`**:`list`, **`batch_size`**:`int`, **`shuffle`**:`bool`)\n",
       "\n",
       "Create a custom ConcatDataset and BatchSampler for modality types."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(create_modality_ds_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multimodal Datasets & Custom Collate Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- https://discuss.pytorch.org/t/train-simultaneously-on-two-datasets/649\n",
    "- This approach  can be used to simultaneously read from 2 Datasets and get a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultimodalDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Multimodal dataset for EHR plus other modalities.\"\"\"\n",
    "\n",
    "    def __init__(self, ds_list):\n",
    "        \"\"\"Separate EHR and other modalities.\"\"\"\n",
    "        self.ehr_ds = ds_list[0]\n",
    "        if len(ds_list) > 1:\n",
    "            self.other_ds_list = ds_list[1:]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"Get patient_ids from EHRDataset and\n",
    "        use them to fetch data of other modalities.\"\"\"\n",
    "\n",
    "        ehr = self.ehr_ds[i]\n",
    "        patient = ehr[0]\n",
    "        ptid = patient.ptid\n",
    "        if hasattr(self, \"other_ds_list\"):\n",
    "            if len(self.other_ds_list) == 1:\n",
    "                return ehr, self.other_ds_list[0][ptid]\n",
    "            else:\n",
    "                return ehr, tuple(ds[ptid] for ds in self.other_ds_list)\n",
    "        else:\n",
    "            return ehr, None\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return count of patients in this modality type.\"\"\"\n",
    "        return len(self.ehr_ds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def collate_ehr(batch):\n",
    "    \"\"\"Custom collate fn for EHR plus 3 other modalities.\"\"\"\n",
    "    ehr, other = zip(*batch)\n",
    "    pts, ys, ms = zip(*ehr)\n",
    "    ys = torch.stack(ys)\n",
    "\n",
    "    if ms[0] in [1, 10, 20]:\n",
    "        other = torch.stack(other)\n",
    "    if ms[0] in [11, 21, 30]:\n",
    "        mod1, mod2 = zip(*other)\n",
    "        other = (torch.stack(mod1), torch.stack(mod2))\n",
    "    if ms[0] == 31:\n",
    "        mod1, mod2, mod3 = zip(*other)\n",
    "        other = (torch.stack(mod1), torch.stack(mod2), torch.stack(mod3))\n",
    "\n",
    "    return pts, ys, ms, other\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quick Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits, mod_types = coherent_splits.get_splits_modtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['0', '21', '30', '31', '11', '1', '20', '10'],\n",
       " 'valid': ['21', '30', '31', '11', '1', '20', '10'],\n",
       " 'test': ['21', '30', '31', '11', '1', '20', '10']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ptlists = splits[\"train\"]\n",
    "train_mod_types = mod_types[\"train\"]\n",
    "assert len(train_ptlists) == len(train_mod_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnimodalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, type: int, tensor_sz):\n",
    "        super().__init__()\n",
    "        self.type = type\n",
    "        self.tensor_sz = tensor_sz\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return torch.full(self.tensor_sz, self.type)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_ds = UnimodalDataset(1, (3,3))\n",
    "ecg_ds = UnimodalDataset(2, (5,))\n",
    "dna_ds = UnimodalDataset(3, (4,2))\n",
    "# notes_ds = UnimodalDataset(\"notes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type0_ehr_ds = EHRDataset(train_ptlists[1], labels, 0)\n",
    "type1_ehr_ds = EHRDataset(train_ptlists[1], labels, 1)\n",
    "type2_ehr_ds = EHRDataset(train_ptlists[1], labels, 21)\n",
    "type3_ehr_ds = EHRDataset(train_ptlists[1], labels, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type0_mm_ds = MultimodalDataset([type0_ehr_ds])\n",
    "type1_mm_ds = MultimodalDataset([type1_ehr_ds, mri_ds])\n",
    "type2_mm_ds = MultimodalDataset([type2_ehr_ds, ecg_ds, mri_ds])\n",
    "type3_mm_ds = MultimodalDataset([type3_ehr_ds, dna_ds, ecg_ds, mri_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, train_sampler = create_modality_ds_sampler([type0_mm_ds, type1_mm_ds, type2_mm_ds, type3_mm_ds], batch_size=4, shuffle=True)\n",
    "train_dl = DataLoader(train_ds,  batch_sampler=train_sampler, num_workers=0, collate_fn=collate_ehr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts, ys, ms, other = next(iter(train_dl))\n",
    "ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None, None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ptid:fbb75ebb-8b10-2a28-5634-3b8f4da7442b, birthdate:1939-08-12, [('heart_failure', True), ('coronary_heart', True)].., device:cpu,\n",
       " ptid:e4aa3da5-5600-6038-9b92-a93278fbe3ed, birthdate:1935-12-22, [('heart_failure', True), ('coronary_heart', False)].., device:cpu,\n",
       " ptid:c12614ed-2db3-cb59-33c6-be45d445192e, birthdate:1930-12-12, [('heart_failure', True), ('coronary_heart', False)].., device:cpu,\n",
       " ptid:53931443-cc8d-9ac0-9ce8-8f3cc30712ab, birthdate:1932-02-20, [('heart_failure', True), ('coronary_heart', True)].., device:cpu)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unimodal Datasets - One Per Modality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class MRIDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, mri_dir: str, tensor_sz: tuple):\n",
    "        super().__init__()\n",
    "        self.mri_dir = mri_dir\n",
    "        self.tensor_sz = tensor_sz\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        mri_fname = glob.glob(f\"{self.mri_dir}/*{i}*\")\n",
    "        if len(mri_fname) == 1:\n",
    "            return torch.full(self.tensor_sz, 1)\n",
    "        else:\n",
    "            raise Exception(f\"MRI filename match error - found {len(mri_fname)} files with ptid: {i}.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class DNADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dna_dir: str, tensor_sz: tuple):\n",
    "        super().__init__()\n",
    "        self.dna_dir = dna_dir\n",
    "        self.tensor_sz = tensor_sz\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        dna_fname = glob.glob(f\"{self.dna_dir}/*{i}*\")\n",
    "        if len(dna_fname) == 1:\n",
    "            return torch.full(self.tensor_sz, 10)\n",
    "        else:\n",
    "            raise Exception(f\"DNA filename match error - found {len(dna_fname)} files with ptid: {i}.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class ECGDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ecg_dir: str, tensor_sz: tuple):\n",
    "        super().__init__()\n",
    "        ecg_data = pd.read_csv(f\"{ecg_dir}/ecg.csv\")\n",
    "        self.ecg_pids = ecg_data.patient.unique()\n",
    "        self.tensor_sz = tensor_sz\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        if i in self.ecg_pids:\n",
    "            return torch.full(self.tensor_sz, 20)\n",
    "        else:\n",
    "            raise Exception(f\"ptid: {i} - not found in ECG data.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mri_ds = MRIDataset(f\"{COHERENT_DATA_STORE}/output/dicom\", (4,4))\n",
    "dna_ds = DNADataset(f\"{COHERENT_DATA_STORE}/output/dna\", (3,2))\n",
    "ecg_ds = ECGDataset(f\"{COHERENT_DATA_STORE}\", (5,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1],\n",
       "        [1, 1, 1, 1]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mri_ds[\"e87a6fbb-f0c0-fac0-4207-93698009e721\"] # exception\n",
    "mri_ds[\"5293a3a9-777a-ffdf-d9ec-3439c0115d231\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10, 10],\n",
       "        [10, 10],\n",
       "        [10, 10]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dna_ds[\"5293a3a9-777a-ffdf-d9ec-3439c0115d231\"] # exception\n",
    "dna_ds[\"e87a6fbb-f0c0-fac0-4207-93698009e721\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([20, 20, 20, 20, 20])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ecg_ds[\"9c452d24-00b0-d58f-4cd5-b82bd6695647\"] # exception\n",
    "ecg_ds[\"9c452d24-00b0-d58f-4cd5-b82bd6695646\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests on Synthea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds(x_train, y_train, x_valid, y_valid, modality_type) -> 'train_ds, valid_ds':\n",
    "    train_ds,valid_ds = EHRDataset(x_train, y_train, modality_type), EHRDataset(x_valid, y_valid, modality_type)\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Lazy Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = get_ds(*labeled.train, *labeled.valid, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(702, 234)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 702)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled.train), len(labeled.x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_ds)==len(labeled.x_train)==len(labeled.y_train)\n",
    "assert len(valid_ds)==len(labeled.y_valid)==len(labeled.x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:0ace3e15-8aa4-41c5-8b90-2408285ebcfe, birthdate:1986-04-02 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:af1495be-5077-4087-98b1-9ff624c7582c, birthdate:2008-07-17 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:f23e12d9-2ec6-4006-b041-ea78d374e9c9, birthdate:2014-09-06 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:1968aa31-5fce-461a-9486-6e385a7b75e7, birthdate:1986-04-11 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:1211c8ff-ab73-49f3-b2ab-87b7a03f6167, birthdate:1972-03-24 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:27a8b7b6-007d-4036-82a7-80a9ab670dcb, birthdate:2005-04-13 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:532696f2-0b76-4eb0-9aea-a74e2fb1bed2, birthdate:1967-05-18 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu],\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb, mb = train_ds[0:7]\n",
    "xb,yb, mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 8]), torch.Size([7, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape, mb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb[0].obs_nums.is_pinned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ptid:0ace3e15-8aa4-41c5-8b90-2408285ebcfe, birthdate:1986-04-02 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([3]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds._test_getitem(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing multimodal with toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyEHR_DS(torch.utils.data.Dataset):\n",
    "    \"\"\"Toy EHR Dataset for testing multimodal functionality.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_labeled: list,\n",
    "        y_labeled: Tensor,\n",
    "        modality_type: int,\n",
    "    ):\n",
    "        # self.m = torch.full((len(x_labeled), 1), modality_type)\n",
    "        self.m = modality_type\n",
    "        self.x, self.y = x_labeled, y_labeled\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def _test_getitem(self, i):\n",
    "        return self.x[i], self.y[i], self.m\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "            return self.x[i], self.y[i], self.m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_ds = ToyEHR_DS(['type1_1', 'type1_2', 'type1_3', 'type1_4'], torch.tensor((1, 0, 1, 0)), 1)\n",
    "type2_ds = ToyEHR_DS(['type2_1', 'type2_2', 'type2_3', 'type2_4', 'type2_5', 'type2_6', 'type2_7'], torch.tensor((1, 0, 1, 0, 0, 1, 1)), 2)\n",
    "type3_ds = ToyEHR_DS(['type3_1', 'type3_2', 'type3_3', 'type3_4', 'type3_5'], torch.tensor((1, 0, 1, 0, 0)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('type2_4', tensor(0), 2), 7)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type2_ds[3], len(type2_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shuffle = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modtype_ds, sampler = create_modality_ds_sampler([type1_ds, type2_ds, type3_ds], batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(modtype_ds,  batch_sampler=sampler)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0 -- x=('type1_1', 'type1_2')\n",
      "i=1 -- x=('type1_3', 'type1_4')\n",
      "i=2 -- x=('type2_1', 'type2_2')\n",
      "i=3 -- x=('type2_3', 'type2_4')\n",
      "i=4 -- x=('type2_5', 'type2_6')\n",
      "i=5 -- x=('type2_7',)\n",
      "i=6 -- x=('type3_1', 'type3_2')\n",
      "i=7 -- x=('type3_3', 'type3_4')\n",
      "i=8 -- x=('type3_5',)\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y, m) in enumerate(dl):\n",
    "    print(f\"i={i} -- x={x}\") #, y:{y} \\n m:{m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shuffle = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_ds, sampler = create_modality_ds_sampler([type1_ds, type2_ds, type3_ds], batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(mm_ds,  batch_sampler=sampler)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0 -- x=('type3_5', 'type3_3')\n",
      "i=1 -- x=('type2_7', 'type2_2')\n",
      "i=2 -- x=('type1_2', 'type1_3')\n",
      "i=3 -- x=('type3_2',)\n",
      "i=4 -- x=('type2_6', 'type2_4')\n",
      "i=5 -- x=('type2_5', 'type2_1')\n",
      "i=6 -- x=('type2_3',)\n",
      "i=7 -- x=('type3_1', 'type3_4')\n",
      "i=8 -- x=('type1_4', 'type1_1')\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y, m) in enumerate(dl):\n",
    "    print(f\"i={i} -- x={x}\") # \\n y:{y} \\n m:{m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single modality type** - for example just EHR tabular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_ds, sampler = create_modality_ds_sampler([type2_ds], batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(mm_ds,  batch_sampler=sampler)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0 -- x=('type2_1', 'type2_2')\n",
      "i=1 -- x=('type2_3', 'type2_4')\n",
      "i=2 -- x=('type2_5', 'type2_6')\n",
      "i=3 -- x=('type2_7',)\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y, m) in enumerate(dl):\n",
    "    print(f\"i={i} -- x={x}\") # \\n y:{y} \\n m:{m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Multimodal functionality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnimodalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, type: str):\n",
    "        super().__init__()\n",
    "        self.type = type\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return f\"{self.type}-{i}\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyMMDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ds_list):\n",
    "        self.ehr_dataset = ds_list[0]\n",
    "        self.other_datasets = ds_list[1:]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        pts, _, _ = self.ehr_dataset[i]\n",
    "        # ptids = [patient.ptid for patient in pts]\n",
    "        return self.ehr_dataset[i], tuple(d[pts] for d in self.other_datasets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ehr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_ehr_ds = ToyEHR_DS(['type1_1', 'type1_2', 'type1_3', 'type1_4'], torch.tensor((1, 0, 1, 0)), 1)\n",
    "type2_ehr_ds = ToyEHR_DS(['type2_1', 'type2_2', 'type2_3', 'type2_4', 'type2_5', 'type2_6', 'type2_7'], torch.tensor((1, 0, 1, 0, 0, 1, 1)), 2)\n",
    "type3_ehr_ds = ToyEHR_DS(['type3_1', 'type3_2', 'type3_3', 'type3_4', 'type3_5'], torch.tensor((1, 0, 1, 0, 0)), 3)\n",
    "\n",
    "ehr_batch_sz = 2\n",
    "\n",
    "mri_ds = UnimodalDataset(\"mri\")\n",
    "ecg_ds = UnimodalDataset(\"ecg\")\n",
    "dna_ds = UnimodalDataset(\"dna\")\n",
    "notes_ds = UnimodalDataset(\"notes\")\n",
    "\n",
    "type1_mm_ds = ToyMMDataset([type1_ehr_ds, mri_ds, ecg_ds])\n",
    "type2_mm_ds = ToyMMDataset([type2_ehr_ds, dna_ds, notes_ds])\n",
    "type3_mm_ds = ToyMMDataset([type3_ehr_ds, notes_ds, mri_ds, ecg_ds])\n",
    "\n",
    "\n",
    "\n",
    "modtype_ds, modtype_sampler = create_modality_ds_sampler([type1_mm_ds, type2_mm_ds, type3_mm_ds], batch_size=ehr_batch_sz, shuffle=True)\n",
    "ehr_dl = DataLoader(modtype_ds,  batch_sampler=modtype_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 11, 16]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modtype_ds.cumulative_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('type2_3', 'type2_5'), tensor([1, 0]), tensor([2, 2])],\n",
       " [('dna-type2_3', 'dna-type2_5'), ('notes-type2_3', 'notes-type2_5')]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(ehr_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tests on Coherent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherent_splits = EHRDataSplits(COHERENT_DATA_STORE,  age_start=240, age_range=120, start_is_date=False, age_in_months=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits, mod_types = coherent_splits.get_splits_modtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['0', '21', '30', '31', '11', '1', '20', '10'],\n",
       " 'valid': ['21', '30', '31', '11', '1', '20', '10'],\n",
       " 'test': ['21', '30', '31', '11', '1', '20', '10']}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "\n",
    "def get_dls(splits: dict, modality_types: dict, labels: list, datastore: str, batch_size: int, num_workers: int):\n",
    "    dls = {}\n",
    "    for split in [\"train\", \"valid\", \"test\"]:\n",
    "\n",
    "        ptlists = splits[split]\n",
    "        mod_types = modality_types[split]\n",
    "        assert len(ptlists) == len(mod_types)\n",
    "\n",
    "        multimodal_ds_list = []\n",
    "        for ptlist, mod_type in zip(ptlists, mod_types):\n",
    "            mod_type = int(mod_type)\n",
    "\n",
    "            unimodal_ds_list = []\n",
    "\n",
    "            # EHR\n",
    "            unimodal_ds_list.append(\n",
    "                EHRDataset(ptlist=ptlist, labels=labels, modality_type=mod_type)\n",
    "            )\n",
    "            # + MRI\n",
    "            if mod_type in [1, 11, 21, 31]:\n",
    "                unimodal_ds_list.append(\n",
    "                    MRIDataset(f\"{datastore}/output/dicom\", (4, 4))\n",
    "                )\n",
    "            # + DNA\n",
    "            if mod_type in [10, 11, 30, 31]:\n",
    "                unimodal_ds_list.append(\n",
    "                    DNADataset(f\"{datastore}/output/dna\", (3, 2))\n",
    "                )\n",
    "            # + ECG\n",
    "            if mod_type in [20, 21, 30, 31]:\n",
    "                unimodal_ds_list.append(ECGDataset(f\"{datastore}\", (5,)))\n",
    "\n",
    "            multimodal_ds_list.append(MultimodalDataset(unimodal_ds_list))\n",
    "\n",
    "        shuffle = True if split == \"train\" else False\n",
    "        ds, sampler = create_modality_ds_sampler(\n",
    "            multimodal_ds_list, batch_size=batch_size, shuffle=shuffle\n",
    "        )\n",
    "        dl = DataLoader(\n",
    "            dataset=ds, batch_sampler=sampler, num_workers=0, collate_fn=collate_ehr\n",
    "        )\n",
    "        dls[split] = dl\n",
    "        \n",
    "    return dls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '21', '30', '31', '11', '1', '20', '10']\n",
      "['21', '30', '31', '11', '1', '20', '10']\n"
     ]
    }
   ],
   "source": [
    "for split in [\"train\", \"valid\"]:\n",
    "    print(mod_types[split])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = get_dls(splits, mod_types, batch_size=4, num_workers=cpu_cnt/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <torch.utils.data.dataloader.DataLoader at 0x7f7e01c84040>,\n",
       " 'valid': <torch.utils.data.dataloader.DataLoader at 0x7f7e01e4b1c0>,\n",
       " 'test': <torch.utils.data.dataloader.DataLoader at 0x7f7e01e77a90>}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = dls[\"train\"]\n",
    "valid_dl = dls[\"valid\"]\n",
    "test_dl = dls[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((ptid:57c53e54-8f99-3393-8cc3-94e98bfbdc68, birthdate:1928-10-29, [('heart_failure', True), ('coronary_heart', False)].., device:cpu,\n",
       "  ptid:f12ff989-9593-71f1-66e6-502ec9b3fecd, birthdate:1946-04-26, [('heart_failure', True), ('coronary_heart', False)].., device:cpu,\n",
       "  ptid:182c006c-b98a-0b2c-39f9-ac12d2ac732b, birthdate:1917-08-14, [('heart_failure', False), ('coronary_heart', True)].., device:cpu,\n",
       "  ptid:2ace6fc1-10d4-dffd-0ad7-0ff8cef81bff, birthdate:1934-12-15, [('heart_failure', True), ('coronary_heart', False)].., device:cpu),\n",
       " tensor([[1., 0., 0., 1., 0.],\n",
       "         [1., 0., 0., 1., 0.],\n",
       "         [0., 1., 0., 1., 1.],\n",
       "         [1., 0., 0., 1., 0.]]),\n",
       " (31, 31, 31, 31),\n",
       " (tensor([[[1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1]],\n",
       "  \n",
       "          [[1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1]],\n",
       "  \n",
       "          [[1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1]],\n",
       "  \n",
       "          [[1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1]]]),\n",
       "  tensor([[[10, 10],\n",
       "           [10, 10],\n",
       "           [10, 10]],\n",
       "  \n",
       "          [[10, 10],\n",
       "           [10, 10],\n",
       "           [10, 10]],\n",
       "  \n",
       "          [[10, 10],\n",
       "           [10, 10],\n",
       "           [10, 10]],\n",
       "  \n",
       "          [[10, 10],\n",
       "           [10, 10],\n",
       "           [10, 10]]]),\n",
       "  tensor([[20, 20, 20, 20, 20],\n",
       "          [20, 20, 20, 20, 20],\n",
       "          [20, 20, 20, 20, 20],\n",
       "          [20, 20, 20, 20, 20]])))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dl))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts, ys, ms, other = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ms[0] == 31:\n",
    "    mri, dna, ecg = other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[20, 20, 20, 20, 20],\n",
       "        [20, 20, 20, 20, 20],\n",
       "        [20, 20, 20, 20, 20],\n",
       "        [20, 20, 20, 20, 20]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((ptid:1a82483d-7eb2-d5e0-1e1f-398ba129b18b, birthdate:1936-12-22, [('heart_failure', True), ('coronary_heart', False)].., device:cpu,\n",
       "  ptid:6dc8bd6b-e2a8-92bf-613d-8b477eb87d7c, birthdate:1911-12-23, [('heart_failure', True), ('coronary_heart', False)].., device:cpu,\n",
       "  ptid:844a37ff-ce26-6338-fd6a-0bc1e925a702, birthdate:1933-03-15, [('heart_failure', True), ('coronary_heart', False)].., device:cpu),\n",
       " tensor([[1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.],\n",
       "         [1., 0., 0., 0., 0.]]),\n",
       " (21, 21, 21),\n",
       " (tensor([[[1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1]],\n",
       "  \n",
       "          [[1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1]],\n",
       "  \n",
       "          [[1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1]]]),\n",
       "  tensor([[20, 20, 20, 20, 20],\n",
       "          [20, 20, 20, 20, 20],\n",
       "          [20, 20, 20, 20, 20]])))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(valid_dl))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((ptid:8f61d438-d822-b7b0-2184-8a0762fc11f3, birthdate:1914-09-18, [('heart_failure', True), ('coronary_heart', False)].., device:cpu,),\n",
       " tensor([[1., 0., 0., 0., 0.]]),\n",
       " (21,),\n",
       " (tensor([[[1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1],\n",
       "           [1, 1, 1, 1]]]),\n",
       "  tensor([[20, 20, 20, 20, 20]])))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(test_dl))\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader - Using Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need to define a custom collate function**, because default collate cannot handle list of patient objects in x, gives following error\n",
    "```\n",
    "TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class '__main__.Patient'>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:8d1ba4bb-7250-4295-be1c-5d0d423e55f7, birthdate:1957-02-13 00:00:00, [('diabetes', True), ('stroke', False)].., device:cpu,\n",
       "  ptid:f1921fc3-fdfc-441d-a928-27c18002fedf, birthdate:1909-12-22 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:fc4aa89c-e441-4c0b-841f-3d16ffe1b235, birthdate:1981-04-24 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:4e0be087-7a33-4655-a9c0-f00f23178ac1, birthdate:1977-02-03 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu],\n",
       " tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tmps,y_tmps, m_tmps = valid_ds[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ptid:8d1ba4bb-7250-4295-be1c-5d0d423e55f7, birthdate:1957-02-13 00:00:00, [('diabetes', True), ('stroke', False)].., device:cpu,\n",
       " ptid:f1921fc3-fdfc-441d-a928-27c18002fedf, birthdate:1909-12-22 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       " ptid:fc4aa89c-e441-4c0b-841f-3d16ffe1b235, birthdate:1981-04-24 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       " ptid:4e0be087-7a33-4655-a9c0-f00f23178ac1, birthdate:1977-02-03 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tmps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tmps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tmps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Old collate fns**\n",
    "\n",
    "**1. removed cuda calls**\n",
    "```python\n",
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return [x.to_gpu() for x in xs], torch.unsqueeze(torch.tensor(ys), 1).cuda()\n",
    "```\n",
    "**2. removed unsqueeze**\n",
    "```python\n",
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return xs, torch.unsqueeze(torch.tensor(ys), 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_ehr(b):\n",
    "    '''Custom collate function for use in `DataLoader`'''\n",
    "    xs,ys, ms = zip(*b)\n",
    "    return xs, torch.stack(ys), torch.stack(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs, collate_fn=collate_ehr, lazy=True) -> 'train_dl, valid_dl':\n",
    "    return(DataLoader(train_ds, batch_size=bs, shuffle=True, collate_fn=collate_fn, pin_memory=lazy),\n",
    "           DataLoader(valid_ds, batch_size=bs*2, collate_fn=collate_fn, pin_memory=lazy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests - `iter()`, `next()` - Next Batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(valid_dl)\n",
    "first_x, first_y, first_m = next(it)\n",
    "second_x, second_y, second_m = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:8d1ba4bb-7250-4295-be1c-5d0d423e55f7, birthdate:1957-02-13 00:00:00, [('diabetes', True), ('stroke', False)].., device:cpu,\n",
       "  ptid:f1921fc3-fdfc-441d-a928-27c18002fedf, birthdate:1909-12-22 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:fc4aa89c-e441-4c0b-841f-3d16ffe1b235, birthdate:1981-04-24 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:4e0be087-7a33-4655-a9c0-f00f23178ac1, birthdate:1977-02-03 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu],\n",
       " tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_x, first_y, first_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_x[3].med_offsts.is_pinned(), first_y.is_pinned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:6d048a56-edb8-4f29-891d-7a84d75a8e78, birthdate:1914-09-05 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:4fc76a3b-e39e-4091-a6af-3595e0cb607e, birthdate:1948-06-01 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:26ca976d-0b5b-4662-af41-535ff670dd5a, birthdate:2014-09-22 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:59486a8b-389b-4355-9df4-edc62bbd1a11, birthdate:1951-10-11 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu],\n",
       " tensor([[0., 0., 1., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_x, second_y, second_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_x[0].alg_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_x[0].alg_nums.is_pinned()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing full GPU loading (non-Lazy)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = EHRDataset(*labeled.train, modality_type=0, lazy_load_gpu=False)\n",
    "valid_ds = EHRDataset(*labeled.valid, modality_type=2, lazy_load_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:0ace3e15-8aa4-41c5-8b90-2408285ebcfe, birthdate:1986-04-02 00:00:00, [('diabetes', False), ('stroke', False)].., device:cuda:0,\n",
       "  ptid:af1495be-5077-4087-98b1-9ff624c7582c, birthdate:2008-07-17 00:00:00, [('diabetes', False), ('stroke', False)].., device:cuda:0,\n",
       "  ptid:f23e12d9-2ec6-4006-b041-ea78d374e9c9, birthdate:2014-09-06 00:00:00, [('diabetes', False), ('stroke', False)].., device:cuda:0,\n",
       "  ptid:1968aa31-5fce-461a-9486-6e385a7b75e7, birthdate:1986-04-11 00:00:00, [('diabetes', False), ('stroke', False)].., device:cuda:0,\n",
       "  ptid:1211c8ff-ab73-49f3-b2ab-87b7a03f6167, birthdate:1972-03-24 00:00:00, [('diabetes', False), ('stroke', False)].., device:cuda:0],\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0'),\n",
       " tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]], device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb,mb = train_ds[0:5]\n",
    "xb,yb,mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb[0].demographics.is_pinned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs, lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tmp, y_tmp, m_tmp = next(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, tensor([2], device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tmp[0].demographics.is_pinned(), m_tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ptid:8d1ba4bb-7250-4295-be1c-5d0d423e55f7, birthdate:1957-02-13 00:00:00, [('diabetes', True), ('stroke', False)].., device:cuda:0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EHRData:\n",
    "    \"\"\"All encompassing class for EHR data\n",
    "    Holds Splits, Labels, Datasets, DataLoaders and\n",
    "    provides convenience fns for training and prediction.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        path,\n",
    "        labels,\n",
    "        age_start,\n",
    "        age_range,\n",
    "        start_is_date,\n",
    "        age_in_months,\n",
    "        lazy_load_gpu=True,\n",
    "    ):\n",
    "        self.path, self.labels = path, labels\n",
    "        self.age_start, self.age_range = age_start, age_range\n",
    "        self.start_is_date, self.age_in_months = start_is_date, age_in_months\n",
    "        self.lazy_load_gpu = lazy_load_gpu\n",
    "\n",
    "    def load_splits(self, modality_type):\n",
    "        \"\"\"Load data splits given dataset path\"\"\"\n",
    "        self.splits = EHRDataSplits(\n",
    "            self.path,\n",
    "            modality_type,\n",
    "            self.age_start,\n",
    "            self.age_range,\n",
    "            self.start_is_date,\n",
    "            self.age_in_months,\n",
    "        )\n",
    "\n",
    "    def label(self):\n",
    "        \"\"\"Run labeler - i.e. extract y from patient objects\"\"\"\n",
    "        self.labeled = LabelEHRData(*self.splits.get_splits(), self.labels)\n",
    "\n",
    "    def create_datasets(self, modality_type):\n",
    "        \"\"\"Create `EHRDataset`s\"\"\"\n",
    "        self.train_ds = EHRDataset(*self.labeled.train, modality_type, self.lazy_load_gpu)\n",
    "        self.valid_ds = EHRDataset(*self.labeled.valid, modality_type, self.lazy_load_gpu)\n",
    "        self.test_ds = EHRDataset(*self.labeled.test, modality_type, self.lazy_load_gpu)\n",
    "\n",
    "    def ehr_collate(b):\n",
    "        \"\"\"Custom collate function for use in `DataLoader`\"\"\"\n",
    "        xs,ys, ms = zip(*b)\n",
    "        return xs, torch.stack(ys), torch.stack(ms)\n",
    "\n",
    "    def create_dls(self, bs, lazy, c_fn=ehr_collate, **kwargs):\n",
    "        \"\"\"Create `DataLoader`s\"\"\"\n",
    "        self.train_dl = DataLoader(\n",
    "            self.train_ds, bs, shuffle=True, collate_fn=c_fn, pin_memory=lazy, **kwargs\n",
    "        )\n",
    "        self.valid_dl = DataLoader(\n",
    "            self.valid_ds, bs * 2, collate_fn=c_fn, pin_memory=lazy, **kwargs\n",
    "        )\n",
    "        self.test_dl = DataLoader(\n",
    "            self.test_ds, bs * 2, collate_fn=c_fn, pin_memory=lazy, **kwargs\n",
    "        )\n",
    "\n",
    "    def _per_modality(self, modality_type, bs=64, num_workers=0):\n",
    "        \"\"\"Return all data per modality.\"\"\"\n",
    "        self.load_splits(modality_type)\n",
    "        self.label()\n",
    "        self.create_datasets(modality_type)\n",
    "        self.create_dls(bs, self.lazy_load_gpu, num_workers=num_workers)\n",
    "\n",
    "        pos_wts_df = self.splits.get_pos_wts(self.labels)\n",
    "        pos_wts = {}\n",
    "        pos_wts[\"train\"] = torch.Tensor(pos_wts[\"train\"].values)\n",
    "        pos_wts[\"valid\"] = torch.Tensor(pos_wts[\"valid\"].values)\n",
    "        pos_wts[\"test\"] = torch.Tensor(pos_wts[\"test\"].values)\n",
    "        return self.train_dl, self.valid_dl, self.test_dl, pos_wts\n",
    "\n",
    "    def get_data(self, bs=64, num_workers=0):\n",
    "        \"\"\"Return all data for every modality.\"\"\"\n",
    "        modality_types = os.listdir(f\"{self.path}/processed\")\n",
    "        data = {}\n",
    "        for m in modality_types:\n",
    "            data[m] = self._per_modality(m, bs, num_workers)\n",
    "        \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.load_splits\" class=\"doc_header\"><code>EHRData.load_splits</code><a href=\"__main__.py#L22\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.load_splits</code>()\n",
       "\n",
       "Load data splits given dataset path"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.load_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.label\" class=\"doc_header\"><code>EHRData.label</code><a href=\"__main__.py#L14\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.label</code>()\n",
       "\n",
       "Run labeler - i.e. extract y from patient objects"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.create_datasets\" class=\"doc_header\"><code>EHRData.create_datasets</code><a href=\"__main__.py#L18\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.create_datasets</code>()\n",
       "\n",
       "Create [`EHRDataset`](/lemonpie/data.html#EHRDataset)s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.create_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.ehr_collate\" class=\"doc_header\"><code>EHRData.ehr_collate</code><a href=\"__main__.py#L24\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.ehr_collate</code>(**`b`**)\n",
       "\n",
       "Custom collate function for use in `DataLoader`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.ehr_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.create_dls\" class=\"doc_header\"><code>EHRData.create_dls</code><a href=\"__main__.py#L29\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.create_dls</code>(**`bs`**, **`lazy`**, **`c_fn`**=*`ehr_collate`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Create `DataLoader`s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.create_dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.get_data\" class=\"doc_header\"><code>EHRData.get_data</code><a href=\"__main__.py#L35\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.get_data</code>(**`bs`**=*`64`*, **`num_workers`**=*`0`*)\n",
       "\n",
       "Convenience function - returns everything needed for training"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.get_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.get_test_data\" class=\"doc_header\"><code>EHRData.get_test_data</code><a href=\"__main__.py#L47\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.get_test_data</code>(**`bs`**=*`64`*, **`num_workers`**=*`0`*)\n",
       "\n",
       "Convenience function - returns everything needed for prediction using test data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.get_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class MultiModalEHRData:\n",
    "    def __init__(\n",
    "        self,\n",
    "        path,\n",
    "        labels,\n",
    "        age_start,\n",
    "        age_range,\n",
    "        start_is_date,\n",
    "        age_in_months,\n",
    "        lazy_load_gpu=True,\n",
    "    ):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_basics.ipynb.\n",
      "Converted 01_preprocessing_clean.ipynb.\n",
      "Converted 02_preprocessing_vocab.ipynb.\n",
      "Converted 03_preprocessing_transform.ipynb.\n",
      "Converted 04_data.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted 06_learn.ipynb.\n",
      "Converted 07_models.ipynb.\n",
      "Converted 08_experiment.ipynb.\n",
      "Converted 999_amp_testing.ipynb.\n",
      "Converted 999_fusion_clean.ipynb.\n",
      "Converted 999_fusion_models.ipynb.\n",
      "Converted 99_quick_walkthru.ipynb.\n",
      "Converted 99_running_exps.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('lemonpie')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
