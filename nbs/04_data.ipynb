{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "> Classes and functions for managing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from lemonpie.basics import *\n",
    "from lemonpie.preprocessing.transform import *\n",
    "from fastai.imports import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting is already done in the raw data before vocab creation.\n",
    "- The following class is to load and manage the pre-processed splits together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EHRDataSplits():\n",
    "    '''Class to hold the PatientList splits'''\n",
    "    def __init__(self, path, age_start, age_range, start_is_date, age_in_months):\n",
    "        self.train, self.valid, self.test = self._load_splits(path, age_start, age_range, start_is_date, age_in_months)\n",
    "    \n",
    "    def _load_splits(self, path, age_start, age_range, start_is_date, age_in_months):\n",
    "        '''Load splits of preprocessed `PatientList`s from persistent store using path'''\n",
    "        train = PatientList.load(path, 'train', age_start, age_range, start_is_date, age_in_months)\n",
    "        valid = PatientList.load(path, 'valid', age_start, age_range, start_is_date, age_in_months)\n",
    "        test  = PatientList.load(path, 'test',  age_start, age_range, start_is_date, age_in_months)\n",
    "        return train, valid, test\n",
    "\n",
    "    def get_splits(self):\n",
    "        '''Return splits'''\n",
    "        return self.train, self.valid, self.test\n",
    "    \n",
    "    def get_lengths(self):\n",
    "        '''Return a dataframe with lengths (# of patients) of the splits (train, valid, test) and total'''\n",
    "        lengths = [len(self.train), len(self.valid), len(self.test), len(self.train)+len(self.valid)+len(self.test)]\n",
    "        return pd.DataFrame(lengths, index=['train','valid','test','total'], columns=['lengths'])\n",
    "    \n",
    "    def get_label_counts(self, labels):\n",
    "        '''Get prevalence counts of labels in each split - returns a dataframe with counts for each split and total count'''\n",
    "        counts = []\n",
    "        for label in labels:\n",
    "            train_count = [self.train[i].conditions[label] == 1 for i in range(len(self.train))].count(True)\n",
    "            valid_count = [self.valid[i].conditions[label] == 1 for i in range(len(self.valid))].count(True)\n",
    "            test_count  = [self.test[i].conditions[label] == 1 for i in range(len(self.test))].count(True)\n",
    "            total_count = train_count+valid_count+test_count\n",
    "            counts.append([train_count, valid_count, test_count, total_count])\n",
    "        return pd.DataFrame(counts, index=labels, columns=['train','valid','test','total'])\n",
    "    \n",
    "    def get_pos_wts(self, labels):\n",
    "        '''Get positive weights to be used in `nn.BCEWithLogitsLoss`'''\n",
    "        pos_counts = self.get_label_counts(labels)\n",
    "        neg_counts = self.get_lengths().transpose().values - pos_counts\n",
    "        return round(neg_counts / pos_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"EHRDataSplits\" class=\"doc_header\"><code>class</code> <code>EHRDataSplits</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>EHRDataSplits</code>(**`path`**, **`age_start`**, **`age_range`**, **`start_is_date`**, **`age_in_months`**)\n",
       "\n",
       "Class to hold the PatientList splits"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits._load_splits\" class=\"doc_header\"><code>EHRDataSplits._load_splits</code><a href=\"__main__.py#L7\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits._load_splits</code>(**`path`**, **`age_start`**, **`age_range`**, **`start_is_date`**, **`age_in_months`**)\n",
       "\n",
       "Load splits of preprocessed [`PatientList`](/lemonpie/preprocessing_transform.html#PatientList)s from persistent store using path"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits._load_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_splits\" class=\"doc_header\"><code>EHRDataSplits.get_splits</code><a href=\"__main__.py#L14\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_splits</code>()\n",
       "\n",
       "Return splits"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_lengths\" class=\"doc_header\"><code>EHRDataSplits.get_lengths</code><a href=\"__main__.py#L18\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_lengths</code>()\n",
       "\n",
       "Return a dataframe with lengths (# of patients) of the splits (train, valid, test) and total"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_label_counts\" class=\"doc_header\"><code>EHRDataSplits.get_label_counts</code><a href=\"__main__.py#L23\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_label_counts</code>(**`labels`**)\n",
       "\n",
       "Get prevalence counts of labels in each split - returns a dataframe with counts for each split and total count"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_pos_wts\" class=\"doc_header\"><code>EHRDataSplits.get_pos_wts</code><a href=\"__main__.py#L34\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_pos_wts</code>(**`labels`**)\n",
       "\n",
       "Get positive weights to be used in `nn.BCEWithLogitsLoss`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_pos_wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/vinod/.lemonpie/datasets/synthea/1K',\n",
       " {'diabetes': '44054006',\n",
       "  'stroke': '230690007',\n",
       "  'alzheimers': '26929004',\n",
       "  'coronary_heart': '53741008',\n",
       "  'lung_cancer': '254637007',\n",
       "  'breast_cancer': '254837009',\n",
       "  'rheumatoid_arthritis': '69896004',\n",
       "  'epilepsy': '84757009'})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_1K, CONDITIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(CONDITIONS.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['diabetes',\n",
       " 'stroke',\n",
       " 'alzheimers',\n",
       " 'coronary_heart',\n",
       " 'lung_cancer',\n",
       " 'breast_cancer',\n",
       " 'rheumatoid_arthritis',\n",
       " 'epilepsy']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = EHRDataSplits(PATH_1K, age_start='2000-01-01', age_range=17, start_is_date=True, age_in_months=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>1171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lengths\n",
       "train      702\n",
       "valid      234\n",
       "test       235\n",
       "total     1171"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = splits.get_lengths()\n",
    "lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alzheimers</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronary_heart</th>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lung_cancer</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rheumatoid_arthritis</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epilepsy</th>\n",
       "      <td>15</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      train  valid  test  total\n",
       "diabetes                 43     14    19     76\n",
       "stroke                   30      7    11     48\n",
       "alzheimers               12      7     6     25\n",
       "coronary_heart           39     11    11     61\n",
       "lung_cancer              12      0     2     14\n",
       "breast_cancer            11      8     2     21\n",
       "rheumatoid_arthritis      2      0     0      2\n",
       "epilepsy                 15      5     2     22"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalence = splits.get_label_counts(labels)\n",
    "prevalence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alzheimers</th>\n",
       "      <td>58.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronary_heart</th>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lung_cancer</th>\n",
       "      <td>58.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>116.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>63.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rheumatoid_arthritis</th>\n",
       "      <td>350.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epilepsy</th>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      train  valid   test  total\n",
       "diabetes               15.0   16.0   11.0   14.0\n",
       "stroke                 22.0   32.0   20.0   23.0\n",
       "alzheimers             58.0   32.0   38.0   46.0\n",
       "coronary_heart         17.0   20.0   20.0   18.0\n",
       "lung_cancer            58.0    inf  116.0   83.0\n",
       "breast_cancer          63.0   28.0  116.0   55.0\n",
       "rheumatoid_arthritis  350.0    inf    inf  584.0\n",
       "epilepsy               46.0   46.0  116.0   52.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits.get_pos_wts(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 702,  234,  235, 1171]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths.transpose().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>659</td>\n",
       "      <td>220</td>\n",
       "      <td>216</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>672</td>\n",
       "      <td>227</td>\n",
       "      <td>224</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alzheimers</th>\n",
       "      <td>690</td>\n",
       "      <td>227</td>\n",
       "      <td>229</td>\n",
       "      <td>1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronary_heart</th>\n",
       "      <td>663</td>\n",
       "      <td>223</td>\n",
       "      <td>224</td>\n",
       "      <td>1110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lung_cancer</th>\n",
       "      <td>690</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>1157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>691</td>\n",
       "      <td>226</td>\n",
       "      <td>233</td>\n",
       "      <td>1150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rheumatoid_arthritis</th>\n",
       "      <td>700</td>\n",
       "      <td>234</td>\n",
       "      <td>235</td>\n",
       "      <td>1169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epilepsy</th>\n",
       "      <td>687</td>\n",
       "      <td>229</td>\n",
       "      <td>233</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      train  valid  test  total\n",
       "diabetes                659    220   216   1095\n",
       "stroke                  672    227   224   1123\n",
       "alzheimers              690    227   229   1146\n",
       "coronary_heart          663    223   224   1110\n",
       "lung_cancer             690    234   233   1157\n",
       "breast_cancer           691    226   233   1150\n",
       "rheumatoid_arthritis    700    234   235   1169\n",
       "epilepsy                687    229   233   1149"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_counts = lengths.transpose().values - prevalence\n",
    "neg_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>15.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>22.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alzheimers</th>\n",
       "      <td>58.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronary_heart</th>\n",
       "      <td>17.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lung_cancer</th>\n",
       "      <td>58.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>116.0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>breast_cancer</th>\n",
       "      <td>63.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rheumatoid_arthritis</th>\n",
       "      <td>350.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>inf</td>\n",
       "      <td>584.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epilepsy</th>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      train  valid   test  total\n",
       "diabetes               15.0   16.0   11.0   14.0\n",
       "stroke                 22.0   32.0   20.0   23.0\n",
       "alzheimers             58.0   32.0   38.0   46.0\n",
       "coronary_heart         17.0   20.0   20.0   18.0\n",
       "lung_cancer            58.0    inf  116.0   83.0\n",
       "breast_cancer          63.0   28.0  116.0   55.0\n",
       "rheumatoid_arthritis  350.0    inf    inf  584.0\n",
       "epilepsy               46.0   46.0  116.0   52.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(neg_counts / prevalence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross check with raw**\n",
    "- Check total counts against raw_csv\n",
    "- Check split counts against split/raw_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cnds = pd.read_csv(f'{PATH_1K}/raw_original/conditions.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['44054006',\n",
       " '230690007',\n",
       " '26929004',\n",
       " '53741008',\n",
       " '254637007',\n",
       " '254837009',\n",
       " '69896004',\n",
       " '84757009']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnd_codes = list(CONDITIONS.values())\n",
    "cnd_codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44054006"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(CONDITIONS['diabetes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diabetes ::  76\n",
      "stroke ::  48\n",
      "alzheimers ::  25\n",
      "coronary_heart ::  61\n",
      "lung_cancer ::  14\n",
      "breast_cancer ::  21\n",
      "rheumatoid_arthritis ::  2\n",
      "epilepsy ::  22\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print(label,':: ', raw_cnds[raw_cnds.CODE == int(CONDITIONS[label])].CODE.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cnds_train = pd.read_csv(f'{PATH_1K}/raw_split/train/conditions.csv', low_memory=False)\n",
    "raw_cnds_valid = pd.read_csv(f'{PATH_1K}/raw_split/valid/conditions.csv', low_memory=False)\n",
    "raw_cnds_test  = pd.read_csv(f'{PATH_1K}/raw_split/test/conditions.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    assert prevalence.loc[label].total == raw_cnds[raw_cnds.CODE == int(CONDITIONS[label])].CODE.count()\n",
    "    assert prevalence.loc[label].train == raw_cnds_train[raw_cnds_train.CODE == int(CONDITIONS[label])].CODE.count()\n",
    "    assert prevalence.loc[label].valid == raw_cnds_valid[raw_cnds_valid.CODE == int(CONDITIONS[label])].CODE.count()\n",
    "    assert prevalence.loc[label].test  == raw_cnds_test [raw_cnds_test.CODE == int(CONDITIONS[label])]. CODE.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labeling** definition in fastai -- some processes need to be run on `train` and **applied** to `valid`\n",
    "\n",
    "This is completed in preprocessing (vocab & transform) as follows\n",
    "1. Vocabs created from train data\n",
    "    - Tokenizing unique values for different record codes & demographic values\n",
    "    - Calculating mean and std for age\n",
    "2. Vocabs applied to train, valid and test data\n",
    "    - With `numericalize` for record codes & demographic values\n",
    "    - With normalizing of age with the mean / std from train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hence labeling in our case will be creating X and y**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X is the patient object\n",
    "- y (for a single patient) needs to be a tensor made out of the patient's values for labels ('diabetes', 'stroke', 'alzheimers', 'coronary_heart', 'lung_cancer') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So **creating the `y` tensor** is simply a matter of ..\n",
    "1. extracting the values of each of the labels from each `Patient` object \n",
    "2. turning it into a `torch.FloatTensor`\n",
    "3. and stacking them up using `torch.stack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 0., 0., 1.], dtype=torch.float64), tensor([1., 0., 0., 1.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_y = np.array((True, False, False, True), dtype='float')\n",
    "torch.from_numpy(tst_y), torch.FloatTensor(tst_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 ways of creating torch tensor from a numpy array, we will stick with the latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for pt in splits.train:\n",
    "    y.append(torch.FloatTensor(np.array([pt.conditions[label] for label in labels], dtype='float')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([702, 8])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(patient_ds, labels) -> 'x,y':\n",
    "    '''Extracts y from patient object, returns x=Patient object, y=tensor of conditions'''\n",
    "    def _get_y(ds, labels):\n",
    "        y = []\n",
    "        for pt in ds:\n",
    "            y.append( torch.FloatTensor(np.array([pt.conditions[label] for label in labels], dtype='float')) )\n",
    "        return torch.stack(y)\n",
    "    \n",
    "    x, y = patient_ds, _get_y(patient_ds, labels)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = label_data(splits.train, labels)\n",
    "x_valid,y_valid = label_data(splits.valid, labels)\n",
    "x_test ,y_test  = label_data(splits.test , labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([702, 8]), torch.Size([234, 8]), torch.Size([235, 8]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2],\n",
       "        [2]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((10,1), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LabelEHRData():\n",
    "    '''Class to hold labeled EHR data splits'''\n",
    "    def __init__(self, train, valid, test, labels):\n",
    "        '''Extracts y from patient object, each labelset a tuple of x,y: x=Patient object, y=tensor of conditions'''\n",
    "        self.x_train, self.y_train = train, self._get_y(train, labels)\n",
    "        self.x_valid, self.y_valid = valid, self._get_y(valid, labels)\n",
    "        self.x_test,  self.y_test  = test , self._get_y(test , labels)\n",
    "        \n",
    "        self.train = self.x_train, self.y_train\n",
    "        self.valid = self.x_valid, self.y_valid\n",
    "        self.test  = self.x_test,  self.y_test\n",
    "    \n",
    "    def _get_y(self, ds, labels):\n",
    "        '''Extract y from each patient object in ds and stack them - ds is dataset containing patient objects'''\n",
    "        y = []\n",
    "        for pt in ds:\n",
    "            y.append( torch.FloatTensor(np.array([pt.conditions[label] for label in labels], dtype='float')) )\n",
    "        return torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"LabelEHRData\" class=\"doc_header\"><code>class</code> <code>LabelEHRData</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>LabelEHRData</code>(**`train`**, **`valid`**, **`test`**, **`labels`**)\n",
       "\n",
       "Class to hold labeled EHR data splits"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LabelEHRData, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LabelEHRData.__init__\" class=\"doc_header\"><code>LabelEHRData.__init__</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>LabelEHRData.__init__</code>(**`train`**, **`valid`**, **`test`**, **`labels`**)\n",
       "\n",
       "Extracts y from patient object, each labelset a tuple of x,y: x=Patient object, y=tensor of conditions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LabelEHRData.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LabelEHRData._get_y\" class=\"doc_header\"><code>LabelEHRData._get_y</code><a href=\"__main__.py#L14\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>LabelEHRData._get_y</code>(**`ds`**, **`labels`**)\n",
       "\n",
       "Extract y from each patient object in ds and stack them - ds is dataset containing patient objects"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LabelEHRData._get_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = LabelEHRData(*splits.get_splits(), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PatientList (702 items)\n",
       " base path:/home/vinod/.lemonpie/datasets/synthea/1K; split:train\n",
       " age_start:2000-01-01; age_range:17; age_type:years\n",
       " ptid:0ace3e15-8aa4-41c5-8b90-2408285ebcfe, birthdate:1986-04-02 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:af1495be-5077-4087-98b1-9ff624c7582c, birthdate:2008-07-17 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:f23e12d9-2ec6-4006-b041-ea78d374e9c9, birthdate:2014-09-06 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:1968aa31-5fce-461a-9486-6e385a7b75e7, birthdate:1986-04-11 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:1211c8ff-ab73-49f3-b2ab-87b7a03f6167, birthdate:1972-03-24 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:27a8b7b6-007d-4036-82a7-80a9ab670dcb, birthdate:2005-04-13 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:532696f2-0b76-4eb0-9aea-a74e2fb1bed2, birthdate:1967-05-18 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:8641e13a-c832-4d97-811a-b735d0abb45e, birthdate:1982-10-06 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:7f874045-4062-405d-8c23-abb12d0af23e, birthdate:1972-05-20 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu\n",
       " ptid:0b6a83ae-fcb1-4b75-9ffa-d52898167d66, birthdate:1989-08-05 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu...],\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled.train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Subclasses](https://pytorch.org/docs/master/data.html?highlight=dataloader#torch.utils.data.Dataset) `torch.utils.data.Dataset`<br>\n",
    "- that is implements `__len__()` and `__getitem__()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EHRDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Class to hold a single EHR dataset (holds a tuple of x, y & m for modality type).\n",
    "    Also handles lazy vs full loading of dataset on GPU.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_labeled: list,\n",
    "        y_labeled: Tensor,\n",
    "        modality_type: int,\n",
    "        lazy_load_gpu: bool = True,\n",
    "    ):\n",
    "        \"\"\"If `lazy_load_gpu` is `False`, load entire dataset on GPU.\"\"\"\n",
    "        self.m = torch.full((len(x_labeled), 1), modality_type)\n",
    "        if lazy_load_gpu:\n",
    "            self.x, self.y = x_labeled, y_labeled\n",
    "            self.lazy = True\n",
    "        else:\n",
    "            self.x = [x.to_gpu() for x in x_labeled]\n",
    "            self.y = y_labeled.to(DEVICE)\n",
    "            self.m = self.m.to(DEVICE)\n",
    "            self.lazy = False\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def _test_getitem(self, i):\n",
    "        return self.x[i], self.y[i], self.m[i]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"If lazy loading, return deep copy of patient object `i`\n",
    "        else entire dataset already on GPU - just return `i`\"\"\"\n",
    "        if self.lazy:\n",
    "            return copy.deepcopy(self.x[i]), self.y[i], self.m[i]\n",
    "        else:\n",
    "            return self.x[i], self.y[i], self.m[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"EHRDataset\" class=\"doc_header\"><code>class</code> <code>EHRDataset</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>EHRDataset</code>(**\\*`args`**, **\\*\\*`kwds`**) :: `Dataset`\n",
       "\n",
       "Class to hold a single EHR dataset (holds a tuple of x, y & m for modality type).\n",
       "Also handles lazy vs full loading of dataset on GPU."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataset, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataset.__init__\" class=\"doc_header\"><code>EHRDataset.__init__</code><a href=\"__main__.py#L6\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataset.__init__</code>(**`x_labeled`**:`list`, **`y_labeled`**:`Tensor`, **`modality_type`**:`int`, **`lazy_load_gpu`**:`bool`=*`True`*)\n",
       "\n",
       "If `lazy_load_gpu` is `False`, load entire dataset on GPU."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataset.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataset.__getitem__\" class=\"doc_header\"><code>EHRDataset.__getitem__</code><a href=\"__main__.py#L30\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataset.__getitem__</code>(**`i`**)\n",
       "\n",
       "If lazy loading, return deep copy of patient object `i`\n",
       "else entire dataset already on GPU - just return `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataset.__getitem__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `Patient` is a custom object and not a typical tensor, we need to handle the behavior for `Dataset`, `DataLoader`, etc to function correctly.\n",
    "- Memory pinning is a good idea for better performance if lazy loading to GPU\n",
    "    - [A discussion - pin memory vs full load to GPU](https://discuss.pytorch.org/t/pin-memory-vs-sending-direct-to-gpu-from-dataset/33891)\n",
    "- So when a DataLoader pins memory on a tensor and copy of the tensor is made on page-locked memory in RAM as opposed to swappable memory which speed up transfers to GPU\n",
    "    - [A good explanation](https://stackoverflow.com/questions/5736968/why-is-cuda-pinned-memory-so-fast)\n",
    "- But on custom data type like our `Patient` object, we need to define the behavior\n",
    "    - [Pytorch docs](https://pytorch.org/docs/stable/data.html#memory-pinning)\n",
    "- Making a [deep copy](https://docs.python.org/3/library/copy.html) of the `Patient`object to mimick tensor behavior\n",
    "    - Otherwise, given the Patient holds it's changed tensors, all tensors are CUDA tensors after the first epoch and DL tries to pin memory again and this causes an error (TODO: Need to elaborate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds(x_train, y_train, x_valid, y_valid, modality_type) -> 'train_ds, valid_ds':\n",
    "    train_ds,valid_ds = EHRDataset(x_train, y_train, modality_type), EHRDataset(x_valid, y_valid, modality_type)\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Lazy Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = get_ds(*labeled.train, *labeled.valid, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(702, 234)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 702)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled.train), len(labeled.x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_ds)==len(labeled.x_train)==len(labeled.y_train)\n",
    "assert len(valid_ds)==len(labeled.y_valid)==len(labeled.x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:0ace3e15-8aa4-41c5-8b90-2408285ebcfe, birthdate:1986-04-02 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:af1495be-5077-4087-98b1-9ff624c7582c, birthdate:2008-07-17 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:f23e12d9-2ec6-4006-b041-ea78d374e9c9, birthdate:2014-09-06 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:1968aa31-5fce-461a-9486-6e385a7b75e7, birthdate:1986-04-11 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:1211c8ff-ab73-49f3-b2ab-87b7a03f6167, birthdate:1972-03-24 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:27a8b7b6-007d-4036-82a7-80a9ab670dcb, birthdate:2005-04-13 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:532696f2-0b76-4eb0-9aea-a74e2fb1bed2, birthdate:1967-05-18 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu],\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb, mb = train_ds[0:7]\n",
    "xb,yb, mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([7, 8]), torch.Size([7, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape, mb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb[0].obs_nums.is_pinned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ptid:0ace3e15-8aa4-41c5-8b90-2408285ebcfe, birthdate:1986-04-02 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([3]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds._test_getitem(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multimodal Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Heirarchy             |   \t|   \t|   \t|   \t|\n",
    "|---\t                |---\t|---\t|---\t|---\t|\n",
    "| ModalityTypeDataset  \t| Different batch sizes  \t|   \t|   \t|   \t|\n",
    "| MultimodalDatasets    | Uniform batch sizes   \t|   \t|   \t|   \t|\n",
    "| UniModalDatasets      |   \t|   \t|   \t|   \t|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modality Type & Multimodal Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`ConcatDataset` & Custom Batch Sampler**\n",
    "\n",
    "Modality type is the combination of data modalities available for a given patient.\n",
    "\n",
    "Solution used here is from this Pytorch forum discussion \n",
    "- https://discuss.pytorch.org/t/how-to-concatenate-different-datasets-each-with-different-dimensions/123218\n",
    "- The `ConcatDataset` holds all the specific `MultimodalDataset`s together - one for each modality combination.\n",
    "    - For example - (EHR + MRI + ECG + Notes), (EHR + MRI), (EHR + DNA + MRI + Notes), etc. \n",
    "- The custom batch sampler ensures that each batch only has elements from one of the `MultimodalDataset`s.\n",
    "    - But also provides shuffling across the various types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "\n",
    "class ModalityTypeBatchSampler(Sampler):\n",
    "    \"\"\"Custom BatchSampler for multimodal data.\"\"\"\n",
    "\n",
    "    def __init__(self, indices_list: list, batch_size: int, shuffle: bool):\n",
    "        \"\"\"Init with indicies from every modality-type dataset and create all batches.\"\"\"\n",
    "        self.indices_list = indices_list\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.all_batches = self._create_batches()\n",
    "\n",
    "    def _chunk(self, indices, size):\n",
    "        \"\"\"Chunk indices into batch size.\"\"\"\n",
    "        return torch.split(torch.tensor(indices), size)\n",
    "\n",
    "    def _create_batches(self):\n",
    "        \"\"\"Create batches.\"\"\"\n",
    "        all_batches = []\n",
    "        for indices in self.indices_list:\n",
    "            if self.shuffle:\n",
    "                random.shuffle(indices)\n",
    "            all_batches.extend(self._chunk(indices, self.batch_size))\n",
    "        all_batches = [batch.tolist() for batch in all_batches]\n",
    "\n",
    "        return all_batches\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterable used by dataloaders.\"\"\"\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.all_batches)\n",
    "        return iter(self.all_batches)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return length based on concated datasets.\"\"\"\n",
    "        return len(self.all_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"ModalityTypeBatchSampler\" class=\"doc_header\"><code>class</code> <code>ModalityTypeBatchSampler</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>ModalityTypeBatchSampler</code>(**\\*`args`**, **\\*\\*`kwds`**) :: `Sampler`\n",
       "\n",
       "Custom BatchSampler for multimodal data."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ModalityTypeBatchSampler, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ModalityTypeBatchSampler.__init__\" class=\"doc_header\"><code>ModalityTypeBatchSampler.__init__</code><a href=\"__main__.py#L6\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ModalityTypeBatchSampler.__init__</code>(**`indices_list`**:`list`, **`batch_size`**:`int`, **`shuffle`**:`bool`)\n",
       "\n",
       "Init with indicies from every modality-type dataset and create all batches."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ModalityTypeBatchSampler.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ModalityTypeBatchSampler._chunk\" class=\"doc_header\"><code>ModalityTypeBatchSampler._chunk</code><a href=\"__main__.py#L13\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ModalityTypeBatchSampler._chunk</code>(**`indices`**, **`size`**)\n",
       "\n",
       "Chunk indices into batch size."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ModalityTypeBatchSampler._chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ModalityTypeBatchSampler._create_batches\" class=\"doc_header\"><code>ModalityTypeBatchSampler._create_batches</code><a href=\"__main__.py#L17\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ModalityTypeBatchSampler._create_batches</code>()\n",
       "\n",
       "Create batches."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ModalityTypeBatchSampler._create_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ModalityTypeBatchSampler.__iter__\" class=\"doc_header\"><code>ModalityTypeBatchSampler.__iter__</code><a href=\"__main__.py#L28\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ModalityTypeBatchSampler.__iter__</code>()\n",
       "\n",
       "Iterable used by dataloaders."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ModalityTypeBatchSampler.__iter__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"ModalityTypeBatchSampler.__len__\" class=\"doc_header\"><code>ModalityTypeBatchSampler.__len__</code><a href=\"__main__.py#L34\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>ModalityTypeBatchSampler.__len__</code>()\n",
       "\n",
       "Return length based on concated datasets."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(ModalityTypeBatchSampler.__len__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def create_modality_ds_sampler(\n",
    "    ehr_dataset_list: list, batch_size: int, shuffle: bool\n",
    "):\n",
    "    \"\"\"Create a custom ConcatDataset and BatchSampler for modality types.\"\"\"\n",
    "\n",
    "    modtype_dataset = torch.utils.data.ConcatDataset(ehr_dataset_list)\n",
    "    indxs = modtype_dataset.cumulative_sizes\n",
    "\n",
    "    indicies_list = []\n",
    "    for i in range(len(ehr_dataset_list)):\n",
    "        if i == 0:\n",
    "            indx_range = range(indxs[0])\n",
    "        else:\n",
    "            indx_range = range(indxs[i - 1], indxs[i])\n",
    "        indicies_list.append(list(indx_range))\n",
    "\n",
    "    batch_sampler = ModalityTypeBatchSampler(indicies_list, batch_size, shuffle)\n",
    "\n",
    "    return modtype_dataset, batch_sampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"create_modality_ds_sampler\" class=\"doc_header\"><code>create_modality_ds_sampler</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>create_modality_ds_sampler</code>(**`ehr_dataset_list`**:`list`, **`batch_size`**:`int`, **`shuffle`**:`bool`)\n",
       "\n",
       "Create a custom ConcatDataset and BatchSampler for modality types."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(create_modality_ds_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multimodal Dataset**\n",
    "- https://discuss.pytorch.org/t/train-simultaneously-on-two-datasets/649\n",
    "- This approach  can be used to simultaneously read from 2 Datasets and get a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Class to hold Datasets of multiple modalities.\"\"\"\n",
    "    def __init__(self, ds_list):\n",
    "        \"\"\"Separate EHR and other modalities.\"\"\"\n",
    "        self.ehr_dataset = ds_list[0]\n",
    "        self.other_datasets = ds_list[1:]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \"\"\"Get patient_ids from EHRDataset and \n",
    "        use them to fetch data of other modalities.\"\"\"\n",
    "        pts, _, _ = self.ehr_dataset[i]\n",
    "        ptids = [patient.ptid for patient in pts]\n",
    "        return self.ehr_dataset[i], tuple(d[pts] for d in self.other_datasets)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return count of patients in this modality type.\"\"\"\n",
    "        return len(self.ehr_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing with toy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyEHR_DS(torch.utils.data.Dataset):\n",
    "    \"\"\"Toy EHR Dataset for testing multimodal functionality.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_labeled: list,\n",
    "        y_labeled: Tensor,\n",
    "        modality_type: int,\n",
    "    ):\n",
    "        # self.m = torch.full((len(x_labeled), 1), modality_type)\n",
    "        self.m = modality_type\n",
    "        self.x, self.y = x_labeled, y_labeled\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def _test_getitem(self, i):\n",
    "        return self.x[i], self.y[i], self.m\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "            return self.x[i], self.y[i], self.m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_ds = ToyEHR_DS(['type1_1', 'type1_2', 'type1_3', 'type1_4'], torch.tensor((1, 0, 1, 0)), 1)\n",
    "type2_ds = ToyEHR_DS(['type2_1', 'type2_2', 'type2_3', 'type2_4', 'type2_5', 'type2_6', 'type2_7'], torch.tensor((1, 0, 1, 0, 0, 1, 1)), 2)\n",
    "type3_ds = ToyEHR_DS(['type3_1', 'type3_2', 'type3_3', 'type3_4', 'type3_5'], torch.tensor((1, 0, 1, 0, 0)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('type2_4', tensor(0), 2), 7)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type2_ds[3], len(type2_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shuffle = False`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modtype_ds, sampler = create_modality_ds_sampler([type1_ds, type2_ds, type3_ds], batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(modtype_ds,  batch_sampler=sampler)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0 -- x=('type1_1', 'type1_2')\n",
      "i=1 -- x=('type1_3', 'type1_4')\n",
      "i=2 -- x=('type2_1', 'type2_2')\n",
      "i=3 -- x=('type2_3', 'type2_4')\n",
      "i=4 -- x=('type2_5', 'type2_6')\n",
      "i=5 -- x=('type2_7',)\n",
      "i=6 -- x=('type3_1', 'type3_2')\n",
      "i=7 -- x=('type3_3', 'type3_4')\n",
      "i=8 -- x=('type3_5',)\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y, m) in enumerate(dl):\n",
    "    print(f\"i={i} -- x={x}\") #, y:{y} \\n m:{m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`shuffle = True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_ds, sampler = create_modality_ds_sampler([type1_ds, type2_ds, type3_ds], batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(mm_ds,  batch_sampler=sampler)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0 -- x=('type3_5', 'type3_3')\n",
      "i=1 -- x=('type2_7', 'type2_2')\n",
      "i=2 -- x=('type1_2', 'type1_3')\n",
      "i=3 -- x=('type3_2',)\n",
      "i=4 -- x=('type2_6', 'type2_4')\n",
      "i=5 -- x=('type2_5', 'type2_1')\n",
      "i=6 -- x=('type2_3',)\n",
      "i=7 -- x=('type3_1', 'type3_4')\n",
      "i=8 -- x=('type1_4', 'type1_1')\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y, m) in enumerate(dl):\n",
    "    print(f\"i={i} -- x={x}\") # \\n y:{y} \\n m:{m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single modality type** - for example just EHR tabular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_ds, sampler = create_modality_ds_sampler([type2_ds], batch_size=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl = DataLoader(mm_ds,  batch_sampler=sampler)\n",
    "len(dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0 -- x=('type2_1', 'type2_2')\n",
      "i=1 -- x=('type2_3', 'type2_4')\n",
      "i=2 -- x=('type2_5', 'type2_6')\n",
      "i=3 -- x=('type2_7',)\n"
     ]
    }
   ],
   "source": [
    "for i, (x, y, m) in enumerate(dl):\n",
    "    print(f\"i={i} -- x={x}\") # \\n y:{y} \\n m:{m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Multimodal functionality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnimodalDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, type: str):\n",
    "        super().__init__()\n",
    "        self.type = type\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return f\"{self.type}-{i}\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToyMMDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, ds_list):\n",
    "        self.ehr_dataset = ds_list[0]\n",
    "        self.other_datasets = ds_list[1:]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        pts, _, _ = self.ehr_dataset[i]\n",
    "        # ptids = [patient.ptid for patient in pts]\n",
    "        return self.ehr_dataset[i], tuple(d[pts] for d in self.other_datasets)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ehr_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type1_ehr_ds = ToyEHR_DS(['type1_1', 'type1_2', 'type1_3', 'type1_4'], torch.tensor((1, 0, 1, 0)), 1)\n",
    "type2_ehr_ds = ToyEHR_DS(['type2_1', 'type2_2', 'type2_3', 'type2_4', 'type2_5', 'type2_6', 'type2_7'], torch.tensor((1, 0, 1, 0, 0, 1, 1)), 2)\n",
    "type3_ehr_ds = ToyEHR_DS(['type3_1', 'type3_2', 'type3_3', 'type3_4', 'type3_5'], torch.tensor((1, 0, 1, 0, 0)), 3)\n",
    "\n",
    "ehr_batch_sz = 2\n",
    "\n",
    "mri_ds = UnimodalDataset(\"mri\")\n",
    "ecg_ds = UnimodalDataset(\"ecg\")\n",
    "dna_ds = UnimodalDataset(\"dna\")\n",
    "notes_ds = UnimodalDataset(\"notes\")\n",
    "\n",
    "type1_mm_ds = ToyMMDataset([type1_ehr_ds, mri_ds, ecg_ds])\n",
    "type2_mm_ds = ToyMMDataset([type2_ehr_ds, dna_ds, notes_ds])\n",
    "type3_mm_ds = ToyMMDataset([type3_ehr_ds, notes_ds, mri_ds, ecg_ds])\n",
    "\n",
    "\n",
    "\n",
    "modtype_ds, modtype_sampler = create_modality_ds_sampler([type1_mm_ds, type2_mm_ds, type3_mm_ds], batch_size=ehr_batch_sz, shuffle=True)\n",
    "ehr_dl = DataLoader(modtype_ds,  batch_sampler=modtype_sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 11, 16]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modtype_ds.cumulative_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('type2_3', 'type2_5'), tensor([1, 0]), tensor([2, 2])],\n",
       " [('dna-type2_3', 'dna-type2_5'), ('notes-type2_3', 'notes-type2_5')]]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(ehr_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(Dataset):\n",
    "    def __init__():\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader - Using Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need to define a custom collate function**, because default collate cannot handle list of patient objects in x, gives following error\n",
    "```\n",
    "TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class '__main__.Patient'>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:8d1ba4bb-7250-4295-be1c-5d0d423e55f7, birthdate:1957-02-13 00:00:00, [('diabetes', True), ('stroke', False)].., device:cpu,\n",
       "  ptid:f1921fc3-fdfc-441d-a928-27c18002fedf, birthdate:1909-12-22 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:fc4aa89c-e441-4c0b-841f-3d16ffe1b235, birthdate:1981-04-24 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:4e0be087-7a33-4655-a9c0-f00f23178ac1, birthdate:1977-02-03 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu],\n",
       " tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tmps,y_tmps, m_tmps = valid_ds[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ptid:8d1ba4bb-7250-4295-be1c-5d0d423e55f7, birthdate:1957-02-13 00:00:00, [('diabetes', True), ('stroke', False)].., device:cpu,\n",
       " ptid:f1921fc3-fdfc-441d-a928-27c18002fedf, birthdate:1909-12-22 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       " ptid:fc4aa89c-e441-4c0b-841f-3d16ffe1b235, birthdate:1981-04-24 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       " ptid:4e0be087-7a33-4655-a9c0-f00f23178ac1, birthdate:1977-02-03 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tmps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tmps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3],\n",
       "        [3],\n",
       "        [3],\n",
       "        [3]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_tmps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Old collate fns**\n",
    "\n",
    "**1. removed cuda calls**\n",
    "```python\n",
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return [x.to_gpu() for x in xs], torch.unsqueeze(torch.tensor(ys), 1).cuda()\n",
    "```\n",
    "**2. removed unsqueeze**\n",
    "```python\n",
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return xs, torch.unsqueeze(torch.tensor(ys), 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_ehr(b):\n",
    "    '''Custom collate function for use in `DataLoader`'''\n",
    "    xs,ys, ms = zip(*b)\n",
    "    return xs, torch.stack(ys), torch.stack(ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs, collate_fn=collate_ehr, lazy=True) -> 'train_dl, valid_dl':\n",
    "    return(DataLoader(train_ds, batch_size=bs, shuffle=True, collate_fn=collate_fn, pin_memory=lazy),\n",
    "           DataLoader(valid_ds, batch_size=bs*2, collate_fn=collate_fn, pin_memory=lazy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests - `iter()`, `next()` - Next Batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(valid_dl)\n",
    "first_x, first_y, first_m = next(it)\n",
    "second_x, second_y, second_m = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:8d1ba4bb-7250-4295-be1c-5d0d423e55f7, birthdate:1957-02-13 00:00:00, [('diabetes', True), ('stroke', False)].., device:cpu,\n",
       "  ptid:f1921fc3-fdfc-441d-a928-27c18002fedf, birthdate:1909-12-22 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:fc4aa89c-e441-4c0b-841f-3d16ffe1b235, birthdate:1981-04-24 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:4e0be087-7a33-4655-a9c0-f00f23178ac1, birthdate:1977-02-03 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu],\n",
       " tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_x, first_y, first_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_x[3].med_offsts.is_pinned(), first_y.is_pinned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:6d048a56-edb8-4f29-891d-7a84d75a8e78, birthdate:1914-09-05 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:4fc76a3b-e39e-4091-a6af-3595e0cb607e, birthdate:1948-06-01 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:26ca976d-0b5b-4662-af41-535ff670dd5a, birthdate:2014-09-22 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu,\n",
       "  ptid:59486a8b-389b-4355-9df4-edc62bbd1a11, birthdate:1951-10-11 00:00:00, [('diabetes', False), ('stroke', False)].., device:cpu],\n",
       " tensor([[0., 0., 1., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]),\n",
       " tensor([[3],\n",
       "         [3],\n",
       "         [3],\n",
       "         [3]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_x, second_y, second_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_x[0].alg_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_x[0].alg_nums.is_pinned()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing full GPU loading (non-Lazy)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = EHRDataset(*labeled.train, modality_type=0, lazy_load_gpu=False)\n",
    "valid_ds = EHRDataset(*labeled.valid, modality_type=2, lazy_load_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:0ace3e15-8aa4-41c5-8b90-2408285ebcfe, birthdate:1986-04-02 00:00:00, [('diabetes', False), ('stroke', False)].., device:cuda:0,\n",
       "  ptid:af1495be-5077-4087-98b1-9ff624c7582c, birthdate:2008-07-17 00:00:00, [('diabetes', False), ('stroke', False)].., device:cuda:0,\n",
       "  ptid:f23e12d9-2ec6-4006-b041-ea78d374e9c9, birthdate:2014-09-06 00:00:00, [('diabetes', False), ('stroke', False)].., device:cuda:0,\n",
       "  ptid:1968aa31-5fce-461a-9486-6e385a7b75e7, birthdate:1986-04-11 00:00:00, [('diabetes', False), ('stroke', False)].., device:cuda:0,\n",
       "  ptid:1211c8ff-ab73-49f3-b2ab-87b7a03f6167, birthdate:1972-03-24 00:00:00, [('diabetes', False), ('stroke', False)].., device:cuda:0],\n",
       " tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0'),\n",
       " tensor([[0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0],\n",
       "         [0]], device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb,mb = train_ds[0:5]\n",
    "xb,yb,mb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb[0].demographics.is_pinned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs, lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tmp, y_tmp, m_tmp = next(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, tensor([2], device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tmp[0].demographics.is_pinned(), m_tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ptid:8d1ba4bb-7250-4295-be1c-5d0d423e55f7, birthdate:1957-02-13 00:00:00, [('diabetes', True), ('stroke', False)].., device:cuda:0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EHRData:\n",
    "    \"\"\"All encompassing class for EHR data\n",
    "    Holds Splits, Labels, Datasets, DataLoaders and\n",
    "    provides convenience fns for training and prediction.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        path,\n",
    "        labels,\n",
    "        age_start,\n",
    "        age_range,\n",
    "        start_is_date,\n",
    "        age_in_months,\n",
    "        lazy_load_gpu=True,\n",
    "    ):\n",
    "        self.path, self.labels = path, labels\n",
    "        self.age_start, self.age_range = age_start, age_range\n",
    "        self.start_is_date, self.age_in_months = start_is_date, age_in_months\n",
    "        self.lazy_load_gpu = lazy_load_gpu\n",
    "\n",
    "    def load_splits(self, modality_type):\n",
    "        \"\"\"Load data splits given dataset path\"\"\"\n",
    "        self.splits = EHRDataSplits(\n",
    "            self.path,\n",
    "            modality_type,\n",
    "            self.age_start,\n",
    "            self.age_range,\n",
    "            self.start_is_date,\n",
    "            self.age_in_months,\n",
    "        )\n",
    "\n",
    "    def label(self):\n",
    "        \"\"\"Run labeler - i.e. extract y from patient objects\"\"\"\n",
    "        self.labeled = LabelEHRData(*self.splits.get_splits(), self.labels)\n",
    "\n",
    "    def create_datasets(self, modality_type):\n",
    "        \"\"\"Create `EHRDataset`s\"\"\"\n",
    "        self.train_ds = EHRDataset(*self.labeled.train, modality_type, self.lazy_load_gpu)\n",
    "        self.valid_ds = EHRDataset(*self.labeled.valid, modality_type, self.lazy_load_gpu)\n",
    "        self.test_ds = EHRDataset(*self.labeled.test, modality_type, self.lazy_load_gpu)\n",
    "\n",
    "    def ehr_collate(b):\n",
    "        \"\"\"Custom collate function for use in `DataLoader`\"\"\"\n",
    "        xs,ys, ms = zip(*b)\n",
    "        return xs, torch.stack(ys), torch.stack(ms)\n",
    "\n",
    "    def create_dls(self, bs, lazy, c_fn=ehr_collate, **kwargs):\n",
    "        \"\"\"Create `DataLoader`s\"\"\"\n",
    "        self.train_dl = DataLoader(\n",
    "            self.train_ds, bs, shuffle=True, collate_fn=c_fn, pin_memory=lazy, **kwargs\n",
    "        )\n",
    "        self.valid_dl = DataLoader(\n",
    "            self.valid_ds, bs * 2, collate_fn=c_fn, pin_memory=lazy, **kwargs\n",
    "        )\n",
    "        self.test_dl = DataLoader(\n",
    "            self.test_ds, bs * 2, collate_fn=c_fn, pin_memory=lazy, **kwargs\n",
    "        )\n",
    "\n",
    "    def _per_modality(self, modality_type, bs=64, num_workers=0):\n",
    "        \"\"\"Return all data per modality.\"\"\"\n",
    "        self.load_splits(modality_type)\n",
    "        self.label()\n",
    "        self.create_datasets(modality_type)\n",
    "        self.create_dls(bs, self.lazy_load_gpu, num_workers=num_workers)\n",
    "\n",
    "        pos_wts_df = self.splits.get_pos_wts(self.labels)\n",
    "        pos_wts = {}\n",
    "        pos_wts[\"train\"] = torch.Tensor(pos_wts[\"train\"].values)\n",
    "        pos_wts[\"valid\"] = torch.Tensor(pos_wts[\"valid\"].values)\n",
    "        pos_wts[\"test\"] = torch.Tensor(pos_wts[\"test\"].values)\n",
    "        return self.train_dl, self.valid_dl, self.test_dl, pos_wts\n",
    "\n",
    "    def get_data(self, bs=64, num_workers=0):\n",
    "        \"\"\"Return all data for every modality.\"\"\"\n",
    "        modality_types = os.listdir(f\"{self.path}/processed\")\n",
    "        data = {}\n",
    "        for m in modality_types:\n",
    "            data[m] = self._per_modality(m, bs, num_workers)\n",
    "        \n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.load_splits\" class=\"doc_header\"><code>EHRData.load_splits</code><a href=\"__main__.py#L22\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.load_splits</code>()\n",
       "\n",
       "Load data splits given dataset path"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.load_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.label\" class=\"doc_header\"><code>EHRData.label</code><a href=\"__main__.py#L14\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.label</code>()\n",
       "\n",
       "Run labeler - i.e. extract y from patient objects"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.create_datasets\" class=\"doc_header\"><code>EHRData.create_datasets</code><a href=\"__main__.py#L18\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.create_datasets</code>()\n",
       "\n",
       "Create [`EHRDataset`](/lemonpie/data.html#EHRDataset)s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.create_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.ehr_collate\" class=\"doc_header\"><code>EHRData.ehr_collate</code><a href=\"__main__.py#L24\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.ehr_collate</code>(**`b`**)\n",
       "\n",
       "Custom collate function for use in `DataLoader`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.ehr_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.create_dls\" class=\"doc_header\"><code>EHRData.create_dls</code><a href=\"__main__.py#L29\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.create_dls</code>(**`bs`**, **`lazy`**, **`c_fn`**=*`ehr_collate`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Create `DataLoader`s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.create_dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.get_data\" class=\"doc_header\"><code>EHRData.get_data</code><a href=\"__main__.py#L35\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.get_data</code>(**`bs`**=*`64`*, **`num_workers`**=*`0`*)\n",
       "\n",
       "Convenience function - returns everything needed for training"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.get_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.get_test_data\" class=\"doc_header\"><code>EHRData.get_test_data</code><a href=\"__main__.py#L47\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.get_test_data</code>(**`bs`**=*`64`*, **`num_workers`**=*`0`*)\n",
       "\n",
       "Convenience function - returns everything needed for prediction using test data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.get_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class MultiModalEHRData:\n",
    "    def __init__(\n",
    "        self,\n",
    "        path,\n",
    "        labels,\n",
    "        age_start,\n",
    "        age_range,\n",
    "        start_is_date,\n",
    "        age_in_months,\n",
    "        lazy_load_gpu=True,\n",
    "    ):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_basics.ipynb.\n",
      "Converted 01_preprocessing_clean.ipynb.\n",
      "Converted 02_preprocessing_vocab.ipynb.\n",
      "Converted 03_preprocessing_transform.ipynb.\n",
      "Converted 04_data.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted 06_learn.ipynb.\n",
      "Converted 07_models.ipynb.\n",
      "Converted 08_experiment.ipynb.\n",
      "Converted 999_MMDS.ipynb.\n",
      "Converted 999_amp_testing.ipynb.\n",
      "Converted 999_fusion.ipynb.\n",
      "Converted 99_quick_walkthru.ipynb.\n",
      "Converted 99_running_exps.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('lemonpie')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
