{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data\n",
    "> Classes and functions for managing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from lemonade.preprocessing.clean import * #for GVs\n",
    "from lemonade.preprocessing.transform import *\n",
    "from fastai.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split is already done in the raw data before vocab creation.\n",
    "- The following class just to hold everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EHRDataSplits():\n",
    "    '''Class to hold the PatientList splits; defaults to loading 0 to 20 years age span'''\n",
    "    def __init__(self, path, age_start=0, age_stop=20, age_in_months=False):\n",
    "        self.train, self.valid, self.test = self._load_splits(path, age_start, age_stop, age_in_months)\n",
    "    \n",
    "    def _load_splits(self, path, age_start, age_stop, age_in_months):\n",
    "        '''Load splits of preprocessed `PatientList`s from persistent store using path'''\n",
    "        train = PatientList.load(path, 'train', age_start, age_stop, age_in_months)\n",
    "        valid = PatientList.load(path, 'valid', age_start, age_stop, age_in_months)\n",
    "        test  = PatientList.load(path, 'test',  age_start, age_stop, age_in_months)\n",
    "        return train, valid, test\n",
    "\n",
    "    def get_splits(self):\n",
    "        '''Return splits'''\n",
    "        return self.train, self.valid, self.test\n",
    "    \n",
    "    def get_lengths(self):\n",
    "        '''Return a dataframe with lengths (# of patients) of the splits (train, valid, test) and total'''\n",
    "        lengths = [len(self.train), len(self.valid), len(self.test), len(self.train)+len(self.valid)+len(self.test)]\n",
    "        return pd.DataFrame(lengths, index=['train','valid','test','total'], columns=['lengths'])\n",
    "    \n",
    "    def get_label_counts(self, labels):\n",
    "        '''Get prevalence counts of labels in each split - returns a dataframe with counts for each split and total count'''\n",
    "        counts = []\n",
    "        for label in labels:\n",
    "            train_count = [getattr(self.train[i],label) == 1 for i in range(len(self.train))].count(True)\n",
    "            valid_count = [getattr(self.valid[i],label) == 1 for i in range(len(self.valid))].count(True)\n",
    "            test_count  = [getattr(self.test[i],label) == 1 for i in range(len(self.test))].count(True)\n",
    "            total_count = train_count+valid_count+test_count\n",
    "            counts.append([train_count, valid_count, test_count, total_count])\n",
    "        return pd.DataFrame(counts, index=labels, columns=['train','valid','test','total'])\n",
    "    \n",
    "    def get_pos_wts(self, labels):\n",
    "        '''Get positive weights to be used in `nn.BCEWithLogitsLoss`'''\n",
    "        pos_counts = self.get_label_counts(labels)\n",
    "        neg_counts = self.get_lengths().transpose().values - pos_counts\n",
    "        return round(neg_counts / pos_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"EHRDataSplits\" class=\"doc_header\"><code>class</code> <code>EHRDataSplits</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>EHRDataSplits</code>(**`path`**, **`age_start`**=*`0`*, **`age_stop`**=*`20`*, **`age_in_months`**=*`False`*)\n",
       "\n",
       "Class to hold the PatientList splits; defaults to loading 0 to 20 years age span"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits._load_splits\" class=\"doc_header\"><code>EHRDataSplits._load_splits</code><a href=\"__main__.py#L7\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits._load_splits</code>(**`path`**, **`age_start`**, **`age_stop`**, **`age_in_months`**)\n",
       "\n",
       "Load splits of preprocessed [`PatientList`](/lemonade/preprocessing_transform#PatientList)s from persistent store using path"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits._load_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_splits\" class=\"doc_header\"><code>EHRDataSplits.get_splits</code><a href=\"__main__.py#L14\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_splits</code>()\n",
       "\n",
       "Return splits"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_lengths\" class=\"doc_header\"><code>EHRDataSplits.get_lengths</code><a href=\"__main__.py#L18\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_lengths</code>()\n",
       "\n",
       "Return a dataframe with lengths (# of patients) of the splits (train, valid, test) and total"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_label_counts\" class=\"doc_header\"><code>EHRDataSplits.get_label_counts</code><a href=\"__main__.py#L23\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_label_counts</code>(**`labels`**)\n",
       "\n",
       "Get prevalence counts of labels in each split - returns a dataframe with counts for each split and total count"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_pos_wts\" class=\"doc_header\"><code>EHRDataSplits.get_pos_wts</code><a href=\"__main__.py#L34\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_pos_wts</code>(**`labels`**)\n",
       "\n",
       "Get positive weights to be used in `nn.BCEWithLogitsLoss`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_pos_wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./datasets/synthea/1K',\n",
       " ['diabetes', 'stroke', 'alzheimers', 'coronaryheart'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_1K, LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pth = PATH_1K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = EHRDataSplits(data_pth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>1108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lengths\n",
       "train      664\n",
       "valid      222\n",
       "test       222\n",
       "total     1108"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits.get_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>37</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>42</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alzheimers</th>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronaryheart</th>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train  valid  test  total\n",
       "diabetes          37     10    14     61\n",
       "stroke            42     14    14     70\n",
       "alzheimers        18      3     5     26\n",
       "coronaryheart     34     12     9     55"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalence = splits.get_label_counts(LABELS)\n",
    "prevalence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross check with raw**\n",
    "- Check total counts against raw_csv\n",
    "- Check split counts against split/raw_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cnds = pd.read_csv(f'{data_pth}/raw_original/conditions.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_cnds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61\n",
      "70\n",
      "26\n",
      "55\n"
     ]
    }
   ],
   "source": [
    "print(raw_cnds[raw_cnds.CODE == 44054006].CODE.count()) #diabetes\n",
    "print(raw_cnds[raw_cnds.CODE == 230690007].CODE.count()) #stroke\n",
    "print(raw_cnds[raw_cnds.CODE == 26929004].CODE.count()) #alzheimers\n",
    "print(raw_cnds[raw_cnds.CODE == 53741008].CODE.count()) #coronary_heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cnds_train = pd.read_csv(f'{PATH_1K}/raw_split/train/conditions.csv', low_memory=False)\n",
    "raw_cnds_valid = pd.read_csv(f'{PATH_1K}/raw_split/valid/conditions.csv', low_memory=False)\n",
    "raw_cnds_test  = pd.read_csv(f'{PATH_1K}/raw_split/test/conditions.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n",
      "10\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(raw_cnds_train[raw_cnds_train.CODE == 44054006].CODE.count()) #diabetes\n",
    "print(raw_cnds_valid[raw_cnds_valid.CODE == 44054006].CODE.count()) #diabetes\n",
    "print(raw_cnds_test [raw_cnds_test.CODE == 44054006].CODE.count()) #diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalence.loc['diabetes'].total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnd_codes = [44054006, 230690007, 26929004, 53741008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44054006 :  diabetes\n",
      "230690007 :  stroke\n",
      "26929004 :  alzheimers\n",
      "53741008 :  coronaryheart\n"
     ]
    }
   ],
   "source": [
    "for code,name in zip(cnd_codes, LABELS):\n",
    "    print(code,': ',name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code, name in zip(cnd_codes, LABELS):\n",
    "    assert prevalence.loc[name].total == raw_cnds[raw_cnds.CODE == code].CODE.count()\n",
    "    assert prevalence.loc[name].train == raw_cnds_train[raw_cnds_train.CODE == code].CODE.count()\n",
    "    assert prevalence.loc[name].valid == raw_cnds_valid[raw_cnds_valid.CODE == code].CODE.count()\n",
    "    assert prevalence.loc[name].test  == raw_cnds_test [raw_cnds_test.CODE == code]. CODE.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labeling** definition in fastai -- some processes need to be run on `train` and **applied** to `valid`\n",
    "\n",
    "This is completed in preprocessing (vocab & transform) as follows\n",
    "1. Vocabs created from train data\n",
    "    - Tokenizing unique values for different record codes & demographic values\n",
    "    - Calculating mean and std for age\n",
    "2. Vocabs applied to train, valid and test data\n",
    "    - With `numericalize` for record codes & demographic values\n",
    "    - With normalizing of age with the mean / std from train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hence labeling in our case will be creating X and y**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X is the patient object\n",
    "- y needs to be a tensor made out of - diabetes, stroke, alzheimers, coronaryheart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So **creating the `y` tensor** is simply a matter of ..\n",
    "1. extracting the values of each of the 4 labels from each `Patient` object \n",
    "2. turning it into a `torch.FloatTensor`\n",
    "3. and stacking them up using `torch.stack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 0., 0., 1.], dtype=torch.float64), tensor([1., 0., 0., 1.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_y = np.array((True, False, False, True), dtype='float')\n",
    "torch.from_numpy(tst_y), torch.FloatTensor(tst_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 ways of creating torch tensor from a numpy array, we will stick with the latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for pt in splits.train:\n",
    "    y.append(torch.FloatTensor(np.array([getattr(pt,label) for label in LABELS], dtype='float')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([664, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(patient_ds, labels) -> 'x,y':\n",
    "    '''Extracts y from patient object, returns x=Patient object, y=tensor of conditions'''\n",
    "    def _get_y(ds, labels):\n",
    "        y = []\n",
    "        for pt in ds:\n",
    "            y.append( torch.FloatTensor(np.array([getattr(pt,label) for label in labels], dtype='float')) )\n",
    "        return torch.stack(y)\n",
    "    \n",
    "    x, y = patient_ds, _get_y(patient_ds, labels)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = label_data(splits.train, LABELS)\n",
    "x_valid,y_valid = label_data(splits.valid, LABELS)\n",
    "x_test ,y_test  = label_data(splits.test , LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([664, 4]), torch.Size([222, 4]), torch.Size([222, 4]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LabelEHRData():\n",
    "    '''Class to hold labeled EHR data splits'''\n",
    "    def __init__(self, train, valid, test, labels):\n",
    "        '''Extracts y from patient object, each labelset a tuple of x,y: x=Patient object, y=tensor of conditions'''\n",
    "        self.x_train, self.y_train = train, self._get_y(train, labels)\n",
    "        self.x_valid, self.y_valid = valid, self._get_y(valid, labels)\n",
    "        self.x_test,  self.y_test  = test , self._get_y(test , labels)\n",
    "        \n",
    "        self.train = self.x_train, self.y_train\n",
    "        self.valid = self.x_valid, self.y_valid\n",
    "        self.test  = self.x_test,  self.y_test\n",
    "    \n",
    "    def _get_y(self, ds, labels):\n",
    "        '''Extract y from each patient object in ds and stack them - ds is dataset containing patient objects'''\n",
    "        y = []\n",
    "        for pt in ds:\n",
    "            y.append( torch.FloatTensor(np.array([getattr(pt,label) for label in labels], dtype='float')) )\n",
    "        return torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"LabelEHRData\" class=\"doc_header\"><code>class</code> <code>LabelEHRData</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>LabelEHRData</code>(**`train`**, **`valid`**, **`test`**, **`labels`**)\n",
       "\n",
       "Class to hold labeled EHR data splits"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LabelEHRData, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LabelEHRData.__init__\" class=\"doc_header\"><code>LabelEHRData.__init__</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>LabelEHRData.__init__</code>(**`train`**, **`valid`**, **`test`**, **`labels`**)\n",
       "\n",
       "Extracts y from patient object, each labelset a tuple of x,y: x=Patient object, y=tensor of conditions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LabelEHRData.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LabelEHRData._get_y\" class=\"doc_header\"><code>LabelEHRData._get_y</code><a href=\"__main__.py#L14\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>LabelEHRData._get_y</code>(**`ds`**, **`labels`**)\n",
       "\n",
       "Extract y from each patient object in ds and stack them - ds is dataset containing patient objects"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LabelEHRData._get_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = LabelEHRData(*splits.get_splits(), LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subclasses Pytorch [`Dataset`](https://pytorch.org/docs/master/data.html?highlight=dataloader#torch.utils.data.Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EHRDataset(torch.utils.data.Dataset):\n",
    "    '''Class to hold a single EHR dataset - holds a tuple of x and y and implements `__len__()` and `__getitem__()`'''\n",
    "    def __init__(self, x, y): self.x,self.y = x,y\n",
    "    def __len__(self): return len(self.x)\n",
    "    def __getitem__(self, i): return self.x[i],self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"EHRDataset\" class=\"doc_header\"><code>class</code> <code>EHRDataset</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>EHRDataset</code>(**\\*`args`**, **\\*\\*`kwds`**) :: `Dataset`\n",
       "\n",
       "Class to hold a single EHR dataset - holds a tuple of x and y and implements `__len__()` and `__getitem__()`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataset, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds(x_train,y_train, x_valid,y_valid) -> 'train_ds, valid_ds':\n",
    "    train_ds,valid_ds = EHRDataset(x_train, y_train), EHRDataset(x_valid, y_valid)\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = get_ds(*labeled.train, *labeled.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(664, 222)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 664)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled.train), len(labeled.x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_ds)==len(labeled.x_train)==len(labeled.y_train)\n",
    "assert len(valid_ds)==len(labeled.y_valid)==len(labeled.x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:12b42348-29bb-4cf4-b878-d419a4c8f067, birthdate:1951-09-04, diabetes:False, device:cpu,\n",
       "  ptid:4c59df3b-042b-42c2-901a-3783d6d77919, birthdate:1979-09-18, diabetes:False, device:cpu,\n",
       "  ptid:8f07e577-7ab4-4e89-ae98-6d394b3929a9, birthdate:1967-01-13, diabetes:False, device:cpu,\n",
       "  ptid:653753d9-a52f-4ef3-b285-bdc3c671293c, birthdate:1971-12-26, diabetes:False, device:cpu,\n",
       "  ptid:1b801001-0bf9-4ad9-b175-9de9bc2d905f, birthdate:1979-11-26, diabetes:False, device:cpu],\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = train_ds[0:5]\n",
    "xb,yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader - Using Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need to define a custom collate function**, because default collate cannot handle list of patient objects in x, gives following error\n",
    "```\n",
    "TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class '__main__.Patient'>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:cb64a8e7-c65c-464c-bb27-270dc00d7ec5, birthdate:1960-05-11, diabetes:False, device:cpu,\n",
       "  ptid:8349dd1f-b916-4e4d-b132-837c1e021c58, birthdate:1963-11-22, diabetes:False, device:cpu,\n",
       "  ptid:bd44cef1-d656-480a-9c10-21d2e26e261f, birthdate:2008-11-10, diabetes:False, device:cpu,\n",
       "  ptid:ace46042-749e-44ba-9c7c-92cf42c00eb1, birthdate:1995-09-21, diabetes:False, device:cpu],\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tmps,y_tmps = valid_ds[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ptid:cb64a8e7-c65c-464c-bb27-270dc00d7ec5, birthdate:1960-05-11, diabetes:False, device:cpu,\n",
       " ptid:8349dd1f-b916-4e4d-b132-837c1e021c58, birthdate:1963-11-22, diabetes:False, device:cpu,\n",
       " ptid:bd44cef1-d656-480a-9c10-21d2e26e261f, birthdate:2008-11-10, diabetes:False, device:cpu,\n",
       " ptid:ace46042-749e-44ba-9c7c-92cf42c00eb1, birthdate:1995-09-21, diabetes:False, device:cpu]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tmps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tmps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Old collate fns**\n",
    "\n",
    "**1. removed cuda calls**\n",
    "```python\n",
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return [x.to_gpu() for x in xs], torch.unsqueeze(torch.tensor(ys), 1).cuda()\n",
    "```\n",
    "**2. removed unsqueeze**\n",
    "```python\n",
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return xs, torch.unsqueeze(torch.tensor(ys), 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_ehr(b):\n",
    "    '''Custom collate function for use in `DataLoader`'''\n",
    "    xs,ys = zip(*b)\n",
    "    return xs, torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs, collate_fn=collate_ehr, **kwargs) -> 'train_dl, valid_dl':\n",
    "    return(DataLoader(train_ds, batch_size=bs, shuffle=True, collate_fn=collate_fn, **kwargs),\n",
    "           DataLoader(valid_ds, batch_size=bs*2, collate_fn=collate_fn, **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests - `iter()`, `next()` - Next Batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(valid_dl)\n",
    "first_x, first_y = next(it)\n",
    "second_x, second_y = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((ptid:cb64a8e7-c65c-464c-bb27-270dc00d7ec5, birthdate:1960-05-11, diabetes:False, device:cpu,\n",
       "  ptid:8349dd1f-b916-4e4d-b132-837c1e021c58, birthdate:1963-11-22, diabetes:False, device:cpu,\n",
       "  ptid:bd44cef1-d656-480a-9c10-21d2e26e261f, birthdate:2008-11-10, diabetes:False, device:cpu,\n",
       "  ptid:ace46042-749e-44ba-9c7c-92cf42c00eb1, birthdate:1995-09-21, diabetes:False, device:cpu),\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1.],\n",
       "         [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_x, first_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((ptid:4cc576ef-e1d9-45b0-9d83-7eb7d091cc6f, birthdate:1943-09-25, diabetes:False, device:cpu,\n",
       "  ptid:ee09a493-5684-498f-b46c-851eb1e7a3db, birthdate:1955-06-05, diabetes:False, device:cpu,\n",
       "  ptid:26b6efd5-7bf6-47b5-9d6a-f3f7338afcba, birthdate:1989-11-22, diabetes:False, device:cpu,\n",
       "  ptid:c118629a-db21-4c34-803e-8249ad79ae51, birthdate:1952-02-18, diabetes:False, device:cpu),\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_x, second_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_x[0].alg_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EHRData:\n",
    "    '''All encompassing class for EHR data - holds Splits, Labels, Datasets, DataLoaders and provides convenience fns for training and prediction'''\n",
    "    def __init__(self, path, labels, age_start=0, age_stop=20, age_in_months=False):\n",
    "        self.path, self.labels = path, labels\n",
    "        self.age_start, self.age_stop, self.age_in_months = age_start, age_stop, age_in_months\n",
    "    \n",
    "    def load_splits(self):\n",
    "        '''Load data splits given dataset path'''\n",
    "        self.splits = EHRDataSplits(self.path, self.age_start, self.age_stop, self.age_in_months)\n",
    "    \n",
    "    def label(self):\n",
    "        '''Run labeler - i.e. extract y from patient objects'''\n",
    "        self.labeled = LabelEHRData(*self.splits.get_splits(), self.labels)\n",
    "        \n",
    "    def create_datasets(self):\n",
    "        '''Create `EHRDataset`s'''\n",
    "        self.train_ds = EHRDataset(*self.labeled.train)\n",
    "        self.valid_ds = EHRDataset(*self.labeled.valid)\n",
    "        self.test_ds  = EHRDataset(*self.labeled.test)\n",
    "        \n",
    "    def ehr_collate(b):\n",
    "        '''Custom collate function for use in `DataLoader`'''\n",
    "        xs,ys = zip(*b)\n",
    "        return xs, torch.stack(ys)\n",
    "    \n",
    "    def create_dls(self, bs, collate_fn=ehr_collate, **kwargs):\n",
    "        '''Create `DataLoader`s'''\n",
    "        self.train_dl = DataLoader(self.train_ds, batch_size=bs, shuffle=True, collate_fn=collate_fn, **kwargs)\n",
    "        self.valid_dl = DataLoader(self.valid_ds, batch_size=bs*2, collate_fn=collate_fn, **kwargs)\n",
    "        self.test_dl  = DataLoader(self.test_ds,  batch_size=bs*2, collate_fn=collate_fn, **kwargs)\n",
    "        \n",
    "    def get_data(self, bs=64, num_workers=0):\n",
    "        '''Convenience function - returns everything needed for training'''\n",
    "        self.load_splits()\n",
    "        self.label()\n",
    "        self.create_datasets()\n",
    "        self.create_dls(bs, num_workers=num_workers)\n",
    "\n",
    "        pos_wts = self.splits.get_pos_wts(self.labels)\n",
    "        train_pos_wts = torch.Tensor(pos_wts['train'].values)\n",
    "        valid_pos_wts = torch.Tensor(pos_wts['valid'].values)\n",
    "#         demograph_dims, rec_dims, demograph_dims_wd, rec_dims_wd = get_all_emb_dims(EhrVocabList.load(self.path), αd)\n",
    "#         return self.train_dl, self.valid_dl, demograph_dims, rec_dims, demograph_dims_wd, rec_dims_wd, train_pos_wts, valid_pos_wts\n",
    "        return self.train_dl, self.valid_dl, train_pos_wts, valid_pos_wts\n",
    "\n",
    "    def get_test_data(self, bs=64, num_workers=0):\n",
    "        '''Convenience function - returns everything needed for prediction using test data'''\n",
    "        self.load_splits()\n",
    "        self.label()\n",
    "        self.create_datasets()\n",
    "        self.create_dls(bs, num_workers=num_workers)\n",
    "                        \n",
    "        pos_wts = self.splits.get_pos_wts(self.labels)\n",
    "        test_pos_wts = torch.Tensor(pos_wts['test'].values)\n",
    "#         demograph_dims, rec_dims, demograph_dims_wd, rec_dims_wd = get_all_emb_dims(EhrVocabList.load(self.path))\n",
    "#         return self.test_dl, demograph_dims, rec_dims, demograph_dims_wd, rec_dims_wd, test_pos_wts\n",
    "        return self.test_dl, test_pos_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.load_splits\" class=\"doc_header\"><code>EHRData.load_splits</code><a href=\"__main__.py#L8\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.load_splits</code>()\n",
       "\n",
       "Load data splits given dataset path"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.load_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.label\" class=\"doc_header\"><code>EHRData.label</code><a href=\"__main__.py#L12\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.label</code>()\n",
       "\n",
       "Run labeler - i.e. extract y from patient objects"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.create_datasets\" class=\"doc_header\"><code>EHRData.create_datasets</code><a href=\"__main__.py#L16\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.create_datasets</code>()\n",
       "\n",
       "Create `EHRDataset`s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.create_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.ehr_collate\" class=\"doc_header\"><code>EHRData.ehr_collate</code><a href=\"__main__.py#L22\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.ehr_collate</code>(**`b`**)\n",
       "\n",
       "Custom collate function for use in `DataLoader`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.ehr_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.create_dls\" class=\"doc_header\"><code>EHRData.create_dls</code><a href=\"__main__.py#L27\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.create_dls</code>(**`bs`**, **`collate_fn`**=*`'ehr_collate'`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Create `DataLoader`s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.create_dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.get_data\" class=\"doc_header\"><code>EHRData.get_data</code><a href=\"__main__.py#L33\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.get_data</code>(**`bs`**=*`64`*, **`num_workers`**=*`0`*)\n",
       "\n",
       "Convenience function - returns everything needed for training"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.get_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.get_test_data\" class=\"doc_header\"><code>EHRData.get_test_data</code><a href=\"__main__.py#L47\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.get_test_data</code>(**`bs`**=*`64`*, **`num_workers`**=*`0`*)\n",
       "\n",
       "Convenience function - returns everything needed for prediction using test data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.get_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_preprocessing_clean.ipynb.\n",
      "Converted 02_preprocessing_vocab.ipynb.\n",
      "Converted 03_preprocessing_transform.ipynb.\n",
      "Converted 04_data.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
