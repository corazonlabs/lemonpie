{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "> Classes and functions for managing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:85% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from lemonpie.basics import *\n",
    "from lemonpie.preprocessing.transform import *\n",
    "from fastai.imports import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split is already done in the raw data before vocab creation.\n",
    "- The following class just to hold everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EHRDataSplits():\n",
    "    '''Class to hold the PatientList splits; defaults to loading 0 to 20 years age span'''\n",
    "    def __init__(self, path, age_start=0, age_stop=20, age_in_months=False):\n",
    "        self.train, self.valid, self.test = self._load_splits(path, age_start, age_stop, age_in_months)\n",
    "    \n",
    "    def _load_splits(self, path, age_start, age_stop, age_in_months):\n",
    "        '''Load splits of preprocessed `PatientList`s from persistent store using path'''\n",
    "        train = PatientList.load(path, 'train', age_start, age_stop, age_in_months)\n",
    "        valid = PatientList.load(path, 'valid', age_start, age_stop, age_in_months)\n",
    "        test  = PatientList.load(path, 'test',  age_start, age_stop, age_in_months)\n",
    "        return train, valid, test\n",
    "\n",
    "    def get_splits(self):\n",
    "        '''Return splits'''\n",
    "        return self.train, self.valid, self.test\n",
    "    \n",
    "    def get_lengths(self):\n",
    "        '''Return a dataframe with lengths (# of patients) of the splits (train, valid, test) and total'''\n",
    "        lengths = [len(self.train), len(self.valid), len(self.test), len(self.train)+len(self.valid)+len(self.test)]\n",
    "        return pd.DataFrame(lengths, index=['train','valid','test','total'], columns=['lengths'])\n",
    "    \n",
    "    def get_label_counts(self, labels):\n",
    "        '''Get prevalence counts of labels in each split - returns a dataframe with counts for each split and total count'''\n",
    "        counts = []\n",
    "        for label in labels:\n",
    "            train_count = [getattr(self.train[i],label) == 1 for i in range(len(self.train))].count(True)\n",
    "            valid_count = [getattr(self.valid[i],label) == 1 for i in range(len(self.valid))].count(True)\n",
    "            test_count  = [getattr(self.test[i],label) == 1 for i in range(len(self.test))].count(True)\n",
    "            total_count = train_count+valid_count+test_count\n",
    "            counts.append([train_count, valid_count, test_count, total_count])\n",
    "        return pd.DataFrame(counts, index=labels, columns=['train','valid','test','total'])\n",
    "    \n",
    "    def get_pos_wts(self, labels):\n",
    "        '''Get positive weights to be used in `nn.BCEWithLogitsLoss`'''\n",
    "        pos_counts = self.get_label_counts(labels)\n",
    "        neg_counts = self.get_lengths().transpose().values - pos_counts\n",
    "        return round(neg_counts / pos_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"EHRDataSplits\" class=\"doc_header\"><code>class</code> <code>EHRDataSplits</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>EHRDataSplits</code>(**`path`**, **`age_start`**=*`0`*, **`age_stop`**=*`20`*, **`age_in_months`**=*`False`*)\n",
       "\n",
       "Class to hold the PatientList splits; defaults to loading 0 to 20 years age span"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits._load_splits\" class=\"doc_header\"><code>EHRDataSplits._load_splits</code><a href=\"__main__.py#L7\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits._load_splits</code>(**`path`**, **`age_start`**, **`age_stop`**, **`age_in_months`**)\n",
       "\n",
       "Load splits of preprocessed [`PatientList`](/lemonpie/preprocessing_transform.html#PatientList)s from persistent store using path"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits._load_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_splits\" class=\"doc_header\"><code>EHRDataSplits.get_splits</code><a href=\"__main__.py#L14\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_splits</code>()\n",
       "\n",
       "Return splits"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_lengths\" class=\"doc_header\"><code>EHRDataSplits.get_lengths</code><a href=\"__main__.py#L18\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_lengths</code>()\n",
       "\n",
       "Return a dataframe with lengths (# of patients) of the splits (train, valid, test) and total"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_label_counts\" class=\"doc_header\"><code>EHRDataSplits.get_label_counts</code><a href=\"__main__.py#L23\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_label_counts</code>(**`labels`**)\n",
       "\n",
       "Get prevalence counts of labels in each split - returns a dataframe with counts for each split and total count"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_label_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataSplits.get_pos_wts\" class=\"doc_header\"><code>EHRDataSplits.get_pos_wts</code><a href=\"__main__.py#L34\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataSplits.get_pos_wts</code>(**`labels`**)\n",
       "\n",
       "Get positive weights to be used in `nn.BCEWithLogitsLoss`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataSplits.get_pos_wts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/home/vinod/.lemonpie/datasets/synthea/1K',\n",
       " ['diabetes', 'stroke', 'alzheimers', 'coronaryheart'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_1K, LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = EHRDataSplits(PATH_1K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>valid</th>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total</th>\n",
       "      <td>1171</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       lengths\n",
       "train      702\n",
       "valid      234\n",
       "test       235\n",
       "total     1171"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits.get_lengths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>valid</th>\n",
       "      <th>test</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>43</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alzheimers</th>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coronaryheart</th>\n",
       "      <td>39</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               train  valid  test  total\n",
       "diabetes          43     14    19     76\n",
       "stroke            30      7    11     48\n",
       "alzheimers        12      7     6     25\n",
       "coronaryheart     39     11    11     61"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalence = splits.get_label_counts(LABELS)\n",
    "prevalence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross check with raw**\n",
    "- Check total counts against raw_csv\n",
    "- Check split counts against split/raw_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[getattr(splits.train[i],'diabetes') == 1 for i in range(len(splits.train))].count(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cnds = pd.read_csv(f'{PATH_1K}/raw_original/conditions.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n",
      "48\n",
      "25\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "print(raw_cnds[raw_cnds.CODE == 44054006].CODE.count()) #diabetes\n",
    "print(raw_cnds[raw_cnds.CODE == 230690007].CODE.count()) #stroke\n",
    "print(raw_cnds[raw_cnds.CODE == 26929004].CODE.count()) #alzheimers\n",
    "print(raw_cnds[raw_cnds.CODE == 53741008].CODE.count()) #coronary_heart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_cnds_train = pd.read_csv(f'{PATH_1K}/raw_split/train/conditions.csv', low_memory=False)\n",
    "raw_cnds_valid = pd.read_csv(f'{PATH_1K}/raw_split/valid/conditions.csv', low_memory=False)\n",
    "raw_cnds_test  = pd.read_csv(f'{PATH_1K}/raw_split/test/conditions.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n",
      "14\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print(raw_cnds_train[raw_cnds_train.CODE == 44054006].CODE.count()) #diabetes\n",
    "print(raw_cnds_valid[raw_cnds_valid.CODE == 44054006].CODE.count()) #diabetes\n",
    "print(raw_cnds_test [raw_cnds_test.CODE == 44054006].CODE.count()) #diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prevalence.loc['diabetes'].total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnd_codes = [44054006, 230690007, 26929004, 53741008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44054006 :  diabetes\n",
      "230690007 :  stroke\n",
      "26929004 :  alzheimers\n",
      "53741008 :  coronaryheart\n"
     ]
    }
   ],
   "source": [
    "for code,name in zip(cnd_codes, LABELS):\n",
    "    print(code,': ',name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code, name in zip(cnd_codes, LABELS):\n",
    "    assert prevalence.loc[name].total == raw_cnds[raw_cnds.CODE == code].CODE.count()\n",
    "    assert prevalence.loc[name].train == raw_cnds_train[raw_cnds_train.CODE == code].CODE.count()\n",
    "    assert prevalence.loc[name].valid == raw_cnds_valid[raw_cnds_valid.CODE == code].CODE.count()\n",
    "    assert prevalence.loc[name].test  == raw_cnds_test [raw_cnds_test.CODE == code]. CODE.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Labeling** definition in fastai -- some processes need to be run on `train` and **applied** to `valid`\n",
    "\n",
    "This is completed in preprocessing (vocab & transform) as follows\n",
    "1. Vocabs created from train data\n",
    "    - Tokenizing unique values for different record codes & demographic values\n",
    "    - Calculating mean and std for age\n",
    "2. Vocabs applied to train, valid and test data\n",
    "    - With `numericalize` for record codes & demographic values\n",
    "    - With normalizing of age with the mean / std from train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hence labeling in our case will be creating X and y**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- X is the patient object\n",
    "- y needs to be a tensor made out of - diabetes, stroke, alzheimers, coronaryheart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So **creating the `y` tensor** is simply a matter of ..\n",
    "1. extracting the values of each of the 4 labels from each `Patient` object \n",
    "2. turning it into a `torch.FloatTensor`\n",
    "3. and stacking them up using `torch.stack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 0., 0., 1.], dtype=torch.float64), tensor([1., 0., 0., 1.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tst_y = np.array((True, False, False, True), dtype='float')\n",
    "torch.from_numpy(tst_y), torch.FloatTensor(tst_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2 ways of creating torch tensor from a numpy array, we will stick with the latter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "for pt in splits.train:\n",
    "    y.append(torch.FloatTensor(np.array([getattr(pt,label) for label in LABELS], dtype='float')) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([702, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putting it into a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_data(patient_ds, labels) -> 'x,y':\n",
    "    '''Extracts y from patient object, returns x=Patient object, y=tensor of conditions'''\n",
    "    def _get_y(ds, labels):\n",
    "        y = []\n",
    "        for pt in ds:\n",
    "            y.append( torch.FloatTensor(np.array([getattr(pt,label) for label in labels], dtype='float')) )\n",
    "        return torch.stack(y)\n",
    "    \n",
    "    x, y = patient_ds, _get_y(patient_ds, labels)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train = label_data(splits.train, LABELS)\n",
    "x_valid,y_valid = label_data(splits.valid, LABELS)\n",
    "x_test ,y_test  = label_data(splits.test , LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([702, 4]), torch.Size([234, 4]), torch.Size([235, 4]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LabelEHRData():\n",
    "    '''Class to hold labeled EHR data splits'''\n",
    "    def __init__(self, train, valid, test, labels):\n",
    "        '''Extracts y from patient object, each labelset a tuple of x,y: x=Patient object, y=tensor of conditions'''\n",
    "        self.x_train, self.y_train = train, self._get_y(train, labels)\n",
    "        self.x_valid, self.y_valid = valid, self._get_y(valid, labels)\n",
    "        self.x_test,  self.y_test  = test , self._get_y(test , labels)\n",
    "        \n",
    "        self.train = self.x_train, self.y_train\n",
    "        self.valid = self.x_valid, self.y_valid\n",
    "        self.test  = self.x_test,  self.y_test\n",
    "    \n",
    "    def _get_y(self, ds, labels):\n",
    "        '''Extract y from each patient object in ds and stack them - ds is dataset containing patient objects'''\n",
    "        y = []\n",
    "        for pt in ds:\n",
    "            y.append( torch.FloatTensor(np.array([getattr(pt,label) for label in labels], dtype='float')) )\n",
    "        return torch.stack(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"LabelEHRData\" class=\"doc_header\"><code>class</code> <code>LabelEHRData</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>LabelEHRData</code>(**`train`**, **`valid`**, **`test`**, **`labels`**)\n",
       "\n",
       "Class to hold labeled EHR data splits"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LabelEHRData, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LabelEHRData.__init__\" class=\"doc_header\"><code>LabelEHRData.__init__</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>LabelEHRData.__init__</code>(**`train`**, **`valid`**, **`test`**, **`labels`**)\n",
       "\n",
       "Extracts y from patient object, each labelset a tuple of x,y: x=Patient object, y=tensor of conditions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LabelEHRData.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LabelEHRData._get_y\" class=\"doc_header\"><code>LabelEHRData._get_y</code><a href=\"__main__.py#L14\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>LabelEHRData._get_y</code>(**`ds`**, **`labels`**)\n",
       "\n",
       "Extract y from each patient object in ds and stack them - ds is dataset containing patient objects"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LabelEHRData._get_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = LabelEHRData(*splits.get_splits(), LABELS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Subclasses](https://pytorch.org/docs/master/data.html?highlight=dataloader#torch.utils.data.Dataset) `torch.utils.data.Dataset`<br>\n",
    "- that is implements `__len__()` and `__getitem__()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EHRDataset(torch.utils.data.Dataset):\n",
    "    '''Class to hold a single EHR dataset (holds a tuple of x and y) -- handles lazy vs full loading of dataset on GPU'''\n",
    "    def __init__(self, x_labeled, y_labeled, lazy_load_gpu=True): \n",
    "        '''If `lazy_load_gpu` is `False`, load entire dataset on GPU'''\n",
    "        if lazy_load_gpu: \n",
    "            self.x, self.y = x_labeled, y_labeled\n",
    "            self.lazy = True\n",
    "        else:             \n",
    "            self.x, self.y = [x.to_gpu() for x in x_labeled], y_labeled.to(DEVICE)\n",
    "            self.lazy = False\n",
    "            \n",
    "    def __len__(self): return len(self.x)\n",
    "   \n",
    "    def _test_getitem(self, i): return self.x[i],self.y[i]\n",
    "    \n",
    "    def __getitem__(self, i): \n",
    "        '''If lazy loading, return deep copy of patient object `i`, else entire dataset already on GPU - just return `i`'''\n",
    "        if self.lazy: \n",
    "            return copy.deepcopy(self.x[i]), self.y[i]\n",
    "        else:\n",
    "            return self.x[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h3 id=\"EHRDataset\" class=\"doc_header\"><code>class</code> <code>EHRDataset</code><a href=\"\" class=\"source_link\" style=\"float:right\">[source]</a></h3>\n",
       "\n",
       "> <code>EHRDataset</code>(**`x_labeled`**, **`y_labeled`**, **`lazy_load_gpu`**=*`True`*) :: `Dataset`\n",
       "\n",
       "Class to hold a single EHR dataset (holds a tuple of x and y) -- handles lazy vs full loading of dataset on GPU"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataset, title_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataset.__init__\" class=\"doc_header\"><code>EHRDataset.__init__</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataset.__init__</code>(**`x_labeled`**, **`y_labeled`**, **`lazy_load_gpu`**=*`True`*)\n",
       "\n",
       "If `lazy_load_gpu` is `False`, load entire dataset on GPU"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataset.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRDataset.__getitem__\" class=\"doc_header\"><code>EHRDataset.__getitem__</code><a href=\"__main__.py#L17\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRDataset.__getitem__</code>(**`i`**)\n",
       "\n",
       "If lazy loading, return deep copy of patient object `i`, else entire dataset already on GPU - just return `i`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRDataset.__getitem__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `Patient` is a custom object and not a typical tensor, we need to handle the behavior for `Dataset`, `DataLoader`, etc to function correctly.\n",
    "- Memory pinning is a good idea for better performance if lazy loading to GPU\n",
    "    - [A discussion - pin memory vs full load to GPU](https://discuss.pytorch.org/t/pin-memory-vs-sending-direct-to-gpu-from-dataset/33891)\n",
    "- So when a DataLoader pins memory on a tensor and copy of the tensor is made on page-locked memory in RAM as opposed to swappable memory which speed up transfers to GPU\n",
    "    - [A good explanation](https://stackoverflow.com/questions/5736968/why-is-cuda-pinned-memory-so-fast)\n",
    "- But on custom data type like our `Patient` object, we need to define the behavior\n",
    "    - [Pytorch docs](https://pytorch.org/docs/stable/data.html#memory-pinning)\n",
    "- Making a [deep copy](https://docs.python.org/3/library/copy.html) of the `Patient`object to mimick tensor behavior\n",
    "    - Otherwise, given the Patient holds it's changed tensors, all tensors are CUDA tensors after the first epoch and DL tries to pin memory again and this causes an error (TODO: Need to elaborate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds(x_train,y_train, x_valid,y_valid) -> 'train_ds, valid_ds':\n",
    "    train_ds,valid_ds = EHRDataset(x_train, y_train), EHRDataset(x_valid, y_valid)\n",
    "    return train_ds, valid_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing Lazy Load**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds = get_ds(*labeled.train, *labeled.valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(702, 234)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds), len(valid_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 702)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled.train), len(labeled.x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(train_ds)==len(labeled.x_train)==len(labeled.y_train)\n",
    "assert len(valid_ds)==len(labeled.y_valid)==len(labeled.x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:0ace3e15-8aa4-41c5-8b90-2408285ebcfe, birthdate:1986-04-02, diabetes:False, device:cpu,\n",
       "  ptid:af1495be-5077-4087-98b1-9ff624c7582c, birthdate:2008-07-17, diabetes:False, device:cpu,\n",
       "  ptid:f23e12d9-2ec6-4006-b041-ea78d374e9c9, birthdate:2014-09-06, diabetes:False, device:cpu,\n",
       "  ptid:1968aa31-5fce-461a-9486-6e385a7b75e7, birthdate:1986-04-11, diabetes:False, device:cpu,\n",
       "  ptid:1211c8ff-ab73-49f3-b2ab-87b7a03f6167, birthdate:1972-03-24, diabetes:False, device:cpu],\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = train_ds[0:5]\n",
    "xb,yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb[0].obs_nums.is_pinned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(ptid:0ace3e15-8aa4-41c5-8b90-2408285ebcfe, birthdate:1986-04-02, diabetes:False, device:cpu,\n",
       " tensor([0., 0., 0., 0.]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds._test_getitem(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader - Using Pytorch DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Need to define a custom collate function**, because default collate cannot handle list of patient objects in x, gives following error\n",
    "```\n",
    "TypeError: default_collate: batch must contain tensors, numpy arrays, numbers, dicts or lists; found <class '__main__.Patient'>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:8d1ba4bb-7250-4295-be1c-5d0d423e55f7, birthdate:1957-02-13, diabetes:True, device:cpu,\n",
       "  ptid:f1921fc3-fdfc-441d-a928-27c18002fedf, birthdate:1909-12-22, diabetes:False, device:cpu,\n",
       "  ptid:fc4aa89c-e441-4c0b-841f-3d16ffe1b235, birthdate:1981-04-24, diabetes:False, device:cpu,\n",
       "  ptid:4e0be087-7a33-4655-a9c0-f00f23178ac1, birthdate:1977-02-03, diabetes:False, device:cpu],\n",
       " tensor([[1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ds[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tmps,y_tmps = valid_ds[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ptid:8d1ba4bb-7250-4295-be1c-5d0d423e55f7, birthdate:1957-02-13, diabetes:True, device:cpu,\n",
       " ptid:f1921fc3-fdfc-441d-a928-27c18002fedf, birthdate:1909-12-22, diabetes:False, device:cpu,\n",
       " ptid:fc4aa89c-e441-4c0b-841f-3d16ffe1b235, birthdate:1981-04-24, diabetes:False, device:cpu,\n",
       " ptid:4e0be087-7a33-4655-a9c0-f00f23178ac1, birthdate:1977-02-03, diabetes:False, device:cpu]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tmps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tmps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Old collate fns**\n",
    "\n",
    "**1. removed cuda calls**\n",
    "```python\n",
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return [x.to_gpu() for x in xs], torch.unsqueeze(torch.tensor(ys), 1).cuda()\n",
    "```\n",
    "**2. removed unsqueeze**\n",
    "```python\n",
    "def collate(b):\n",
    "    xs,ys = zip(*b)\n",
    "    return xs, torch.unsqueeze(torch.tensor(ys), 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_ehr(b):\n",
    "    '''Custom collate function for use in `DataLoader`'''\n",
    "    xs,ys = zip(*b)\n",
    "    return xs, torch.stack(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dls(train_ds, valid_ds, bs, collate_fn=collate_ehr, lazy=True) -> 'train_dl, valid_dl':\n",
    "    return(DataLoader(train_ds, batch_size=bs, shuffle=True, collate_fn=collate_fn, pin_memory=lazy),\n",
    "           DataLoader(valid_ds, batch_size=bs*2, collate_fn=collate_fn, pin_memory=lazy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tests - `iter()`, `next()` - Next Batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(valid_dl)\n",
    "first_x, first_y = next(it)\n",
    "second_x, second_y = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:8d1ba4bb-7250-4295-be1c-5d0d423e55f7, birthdate:1957-02-13, diabetes:True, device:cpu,\n",
       "  ptid:f1921fc3-fdfc-441d-a928-27c18002fedf, birthdate:1909-12-22, diabetes:False, device:cpu,\n",
       "  ptid:fc4aa89c-e441-4c0b-841f-3d16ffe1b235, birthdate:1981-04-24, diabetes:False, device:cpu,\n",
       "  ptid:4e0be087-7a33-4655-a9c0-f00f23178ac1, birthdate:1977-02-03, diabetes:False, device:cpu],\n",
       " tensor([[1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_x, first_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_x[3].med_offsts.is_pinned(), first_y.is_pinned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:6d048a56-edb8-4f29-891d-7a84d75a8e78, birthdate:1914-09-05, diabetes:False, device:cpu,\n",
       "  ptid:4fc76a3b-e39e-4091-a6af-3595e0cb607e, birthdate:1948-06-01, diabetes:False, device:cpu,\n",
       "  ptid:26ca976d-0b5b-4662-af41-535ff670dd5a, birthdate:2014-09-22, diabetes:False, device:cpu,\n",
       "  ptid:59486a8b-389b-4355-9df4-edc62bbd1a11, birthdate:1951-10-11, diabetes:False, device:cpu],\n",
       " tensor([[0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_x, second_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_x[0].alg_nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_x[0].alg_nums.is_pinned()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing full GPU loading (non-Lazy)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds,valid_ds = EHRDataset(*labeled.train, lazy_load_gpu=False), EHRDataset(*labeled.valid, lazy_load_gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([ptid:0ace3e15-8aa4-41c5-8b90-2408285ebcfe, birthdate:1986-04-02, diabetes:False, device:cuda:0,\n",
       "  ptid:af1495be-5077-4087-98b1-9ff624c7582c, birthdate:2008-07-17, diabetes:False, device:cuda:0,\n",
       "  ptid:f23e12d9-2ec6-4006-b041-ea78d374e9c9, birthdate:2014-09-06, diabetes:False, device:cuda:0,\n",
       "  ptid:1968aa31-5fce-461a-9486-6e385a7b75e7, birthdate:1986-04-11, diabetes:False, device:cuda:0,\n",
       "  ptid:1211c8ff-ab73-49f3-b2ab-87b7a03f6167, birthdate:1972-03-24, diabetes:False, device:cuda:0],\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]], device='cuda:0'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb,yb = train_ds[0:5]\n",
    "xb,yb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xb[0].demographics.is_pinned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, valid_dl = get_dls(train_ds, valid_ds, bs, lazy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tmp, y_tmp = next(iter(valid_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tmp[0].demographics.is_pinned()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ptid:8d1ba4bb-7250-4295-be1c-5d0d423e55f7, birthdate:1957-02-13, diabetes:True, device:cuda:0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tmp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class EHRData:\n",
    "    '''All encompassing class for EHR data - holds Splits, Labels, Datasets, DataLoaders and provides convenience fns for training and prediction'''\n",
    "    def __init__(self, path, labels, age_start=0, age_stop=20, age_in_months=False, lazy_load_gpu=True):\n",
    "        self.path, self.labels = path, labels\n",
    "        self.age_start, self.age_stop, self.age_in_months = age_start, age_stop, age_in_months\n",
    "        self.lazy_load_gpu = lazy_load_gpu\n",
    "    \n",
    "    def load_splits(self):\n",
    "        '''Load data splits given dataset path'''\n",
    "        self.splits = EHRDataSplits(self.path, self.age_start, self.age_stop, self.age_in_months)\n",
    "    \n",
    "    def label(self):\n",
    "        '''Run labeler - i.e. extract y from patient objects'''\n",
    "        self.labeled = LabelEHRData(*self.splits.get_splits(), self.labels)\n",
    "        \n",
    "    def create_datasets(self):\n",
    "        '''Create `EHRDataset`s'''\n",
    "        self.train_ds = EHRDataset(*self.labeled.train, self.lazy_load_gpu)\n",
    "        self.valid_ds = EHRDataset(*self.labeled.valid, self.lazy_load_gpu)\n",
    "        self.test_ds  = EHRDataset(*self.labeled.test, self.lazy_load_gpu)\n",
    "        \n",
    "    def ehr_collate(b):\n",
    "        '''Custom collate function for use in `DataLoader`'''\n",
    "        xs,ys = zip(*b)\n",
    "        return xs, torch.stack(ys)\n",
    "    \n",
    "    def create_dls(self, bs, lazy, c_fn=ehr_collate, **kwargs):\n",
    "        '''Create `DataLoader`s'''\n",
    "        self.train_dl = DataLoader(self.train_ds, bs, shuffle=True, collate_fn=c_fn, pin_memory=lazy, **kwargs)\n",
    "        self.valid_dl = DataLoader(self.valid_ds, bs*2, collate_fn=c_fn, pin_memory=lazy, **kwargs)\n",
    "        self.test_dl  = DataLoader(self.test_ds,  bs*2, collate_fn=c_fn, pin_memory=lazy, **kwargs)\n",
    "        \n",
    "    def get_data(self, bs=64, num_workers=0):\n",
    "        '''Convenience function - returns everything needed for training'''\n",
    "        self.load_splits()\n",
    "        self.label()\n",
    "        self.create_datasets()\n",
    "        self.create_dls(bs, self.lazy_load_gpu, num_workers=num_workers)\n",
    "\n",
    "        pos_wts = self.splits.get_pos_wts(self.labels)\n",
    "        train_pos_wts = torch.Tensor(pos_wts['train'].values)\n",
    "        valid_pos_wts = torch.Tensor(pos_wts['valid'].values)\n",
    "        return self.train_dl, self.valid_dl, train_pos_wts, valid_pos_wts\n",
    "\n",
    "    def get_test_data(self, bs=64, num_workers=0):\n",
    "        '''Convenience function - returns everything needed for prediction using test data'''\n",
    "        self.load_splits()\n",
    "        self.label()\n",
    "        self.create_datasets()\n",
    "        self.create_dls(bs, self.lazy_load_gpu, num_workers=num_workers)\n",
    "                        \n",
    "        pos_wts = self.splits.get_pos_wts(self.labels)\n",
    "        test_pos_wts = torch.Tensor(pos_wts['test'].values)\n",
    "        return self.test_dl, test_pos_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.load_splits\" class=\"doc_header\"><code>EHRData.load_splits</code><a href=\"__main__.py#L9\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.load_splits</code>()\n",
       "\n",
       "Load data splits given dataset path"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.load_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.label\" class=\"doc_header\"><code>EHRData.label</code><a href=\"__main__.py#L13\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.label</code>()\n",
       "\n",
       "Run labeler - i.e. extract y from patient objects"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.create_datasets\" class=\"doc_header\"><code>EHRData.create_datasets</code><a href=\"__main__.py#L17\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.create_datasets</code>()\n",
       "\n",
       "Create [`EHRDataset`](/lemonpie/data.html#EHRDataset)s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.create_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.ehr_collate\" class=\"doc_header\"><code>EHRData.ehr_collate</code><a href=\"__main__.py#L23\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.ehr_collate</code>(**`b`**)\n",
       "\n",
       "Custom collate function for use in `DataLoader`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.ehr_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.create_dls\" class=\"doc_header\"><code>EHRData.create_dls</code><a href=\"__main__.py#L28\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.create_dls</code>(**`bs`**, **`lazy`**, **`c_fn`**=*`ehr_collate`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Create `DataLoader`s"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.create_dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.get_data\" class=\"doc_header\"><code>EHRData.get_data</code><a href=\"__main__.py#L34\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.get_data</code>(**`bs`**=*`64`*, **`num_workers`**=*`0`*)\n",
       "\n",
       "Convenience function - returns everything needed for training"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.get_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EHRData.get_test_data\" class=\"doc_header\"><code>EHRData.get_test_data</code><a href=\"__main__.py#L46\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EHRData.get_test_data</code>(**`bs`**=*`64`*, **`num_workers`**=*`0`*)\n",
       "\n",
       "Convenience function - returns everything needed for prediction using test data"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(EHRData.get_test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_basics.ipynb.\n",
      "Converted 01_preprocessing_clean.ipynb.\n",
      "Converted 02_preprocessing_vocab.ipynb.\n",
      "Converted 03_preprocessing_transform.ipynb.\n",
      "Converted 04_data.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted 06_learn.ipynb.\n",
      "Converted 07_models.ipynb.\n",
      "Converted 08_experiment.ipynb.\n",
      "Converted 99_quick_walkthru.ipynb.\n",
      "Converted 99_running_exps.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import *\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
